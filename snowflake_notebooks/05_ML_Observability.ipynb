{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Observability Suite - Snowflake Native\n",
        "## Financial Services Model Monitoring & Drift Detection\n",
        "\n",
        "This notebook demonstrates Snowflake's ML Observability capabilities for production model monitoring.\n",
        "\n",
        "## What We'll Cover\n",
        "- Model performance monitoring with automatic drift detection\n",
        "- Data quality monitoring and alerting\n",
        "- Business impact tracking and ROI measurement\n",
        "- Production-ready monitoring dashboards\n",
        "\n",
        "## ML Observability Features\n",
        "- **Performance Tracking**: Accuracy, precision, recall, F1, AUC\n",
        "- **Drift Detection**: Feature drift, prediction drift, concept drift\n",
        "- **Data Quality**: Completeness, validity, consistency monitoring\n",
        "- **Alerting System**: Automated alerts for performance degradation\n",
        "- **Business Metrics**: Revenue impact, cost savings, ROI tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import snowflake.snowpark as snowpark\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import *\n",
        "from snowflake.ml.model_observability import ModelMonitor\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get active session\n",
        "session = snowpark.session._get_active_session()\n",
        "\n",
        "print(f\"üèîÔ∏è Snowflake ML Observability Suite\")\n",
        "print(f\"Database: {session.get_current_database()}\")\n",
        "print(f\"Schema: {session.get_current_schema()}\")\n",
        "print(f\"Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup ML Observability Infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ML Observability infrastructure\n",
        "print(\"üõ†Ô∏è Setting up ML Observability infrastructure...\")\n",
        "\n",
        "# 1. Create inference logging table (core requirement for ML Observability)\n",
        "inference_table_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE ml_inference_logs (\n",
        "    inference_id STRING PRIMARY KEY,\n",
        "    model_name STRING NOT NULL,\n",
        "    model_version STRING NOT NULL,\n",
        "    timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "    \n",
        "    -- Client context\n",
        "    client_id STRING,\n",
        "    \n",
        "    -- Input features (for drift detection)\n",
        "    total_events_30d INTEGER,\n",
        "    web_visits_30d INTEGER,\n",
        "    email_opens_30d INTEGER,\n",
        "    engagement_frequency DECIMAL(10,4),\n",
        "    annual_income INTEGER,\n",
        "    current_401k_balance DECIMAL(12,2),\n",
        "    age INTEGER,\n",
        "    service_tier STRING,\n",
        "    \n",
        "    -- Model predictions\n",
        "    conversion_probability DECIMAL(5,4),\n",
        "    churn_probability DECIMAL(5,4),\n",
        "    recommended_action STRING,\n",
        "    prediction_confidence DECIMAL(5,4),\n",
        "    \n",
        "    -- Ground truth (when available)\n",
        "    actual_conversion BOOLEAN,\n",
        "    actual_churn BOOLEAN,\n",
        "    \n",
        "    -- Quality metrics\n",
        "    inference_latency_ms INTEGER,\n",
        "    data_quality_score DECIMAL(5,4)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(inference_table_sql).collect()\n",
        "print(\"‚úÖ Created ml_inference_logs table\")\n",
        "\n",
        "# 2. Create performance tracking table\n",
        "performance_table_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE ml_model_performance (\n",
        "    performance_id STRING PRIMARY KEY,\n",
        "    model_name STRING NOT NULL,\n",
        "    model_version STRING NOT NULL,\n",
        "    evaluation_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "    accuracy DECIMAL(5,4),\n",
        "    precision_score DECIMAL(5,4),\n",
        "    recall_score DECIMAL(5,4),\n",
        "    f1_score DECIMAL(5,4),\n",
        "    auc_score DECIMAL(5,4),\n",
        "    total_inferences INTEGER,\n",
        "    drift_score DECIMAL(5,4),\n",
        "    data_quality_score DECIMAL(5,4)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(performance_table_sql).collect()\n",
        "print(\"‚úÖ Created ml_model_performance table\")\n",
        "\n",
        "# 3. Create alerts table\n",
        "alerts_table_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE ml_observability_alerts (\n",
        "    alert_id STRING PRIMARY KEY,\n",
        "    alert_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
        "    alert_type STRING,\n",
        "    severity STRING,\n",
        "    model_name STRING,\n",
        "    alert_message STRING,\n",
        "    current_value DECIMAL(10,4),\n",
        "    threshold_value DECIMAL(10,4),\n",
        "    status STRING DEFAULT 'open'\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(alerts_table_sql).collect()\n",
        "print(\"‚úÖ Created ml_observability_alerts table\")\n",
        "\n",
        "print(\"üéØ ML Observability infrastructure ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Simulate Inference Data with Ground Truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic inference data with ground truth for monitoring\n",
        "print(\"üìä Generating inference data with ground truth...\")\n",
        "\n",
        "inference_data_sql = \"\"\"\n",
        "WITH inference_simulation AS (\n",
        "  SELECT \n",
        "    'inf_' || seq8() as inference_id,\n",
        "    'CONVERSION_PREDICTOR_V1' as model_name,\n",
        "    'V1.0' as model_version,\n",
        "    DATEADD(minute, -UNIFORM(1, 10080, RANDOM()), CURRENT_TIMESTAMP()) as timestamp,\n",
        "    \n",
        "    -- Sample client data\n",
        "    'client_' || UNIFORM(1, 50000, RANDOM()) as client_id,\n",
        "    UNIFORM(10, 100, RANDOM()) as total_events_30d,\n",
        "    UNIFORM(5, 50, RANDOM()) as web_visits_30d,\n",
        "    UNIFORM(2, 20, RANDOM()) as email_opens_30d,\n",
        "    ROUND(UNIFORM(0.1, 2.0, RANDOM()), 4) as engagement_frequency,\n",
        "    UNIFORM(30000, 150000, RANDOM()) as annual_income,\n",
        "    UNIFORM(10000, 300000, RANDOM()) as current_401k_balance,\n",
        "    UNIFORM(25, 65, RANDOM()) as age,\n",
        "    CASE \n",
        "      WHEN UNIFORM(0, 1, RANDOM()) < 0.6 THEN 'Basic'\n",
        "      WHEN UNIFORM(0, 1, RANDOM()) < 0.9 THEN 'Premium'\n",
        "      ELSE 'Elite'\n",
        "    END as service_tier,\n",
        "    \n",
        "    -- Simulated model predictions\n",
        "    ROUND(UNIFORM(0.1, 0.9, RANDOM()), 4) as conversion_probability,\n",
        "    ROUND(UNIFORM(0.1, 0.7, RANDOM()), 4) as churn_probability,\n",
        "    CASE \n",
        "      WHEN UNIFORM(0, 1, RANDOM()) < 0.3 THEN 'Wealth_Advisory_Consultation'\n",
        "      WHEN UNIFORM(0, 1, RANDOM()) < 0.6 THEN 'Schedule_Planning_Session'\n",
        "      ELSE 'Educational_Content'\n",
        "    END as recommended_action,\n",
        "    ROUND(UNIFORM(0.5, 1.0, RANDOM()), 4) as prediction_confidence,\n",
        "    \n",
        "    -- Simulated ground truth (with realistic correlation to predictions)\n",
        "    CASE \n",
        "      WHEN conversion_probability > 0.7 AND UNIFORM(0, 1, RANDOM()) < 0.8 THEN TRUE\n",
        "      WHEN conversion_probability > 0.5 AND UNIFORM(0, 1, RANDOM()) < 0.6 THEN TRUE\n",
        "      WHEN conversion_probability > 0.3 AND UNIFORM(0, 1, RANDOM()) < 0.3 THEN TRUE\n",
        "      ELSE FALSE\n",
        "    END as actual_conversion,\n",
        "    \n",
        "    CASE \n",
        "      WHEN churn_probability > 0.6 AND UNIFORM(0, 1, RANDOM()) < 0.7 THEN TRUE\n",
        "      WHEN churn_probability > 0.4 AND UNIFORM(0, 1, RANDOM()) < 0.4 THEN TRUE\n",
        "      ELSE FALSE\n",
        "    END as actual_churn,\n",
        "    \n",
        "    UNIFORM(10, 100, RANDOM()) as inference_latency_ms,\n",
        "    ROUND(UNIFORM(0.85, 1.0, RANDOM()), 4) as data_quality_score\n",
        "    \n",
        "  FROM TABLE(GENERATOR(ROWCOUNT => 5000))\n",
        ")\n",
        "\n",
        "SELECT * FROM inference_simulation\n",
        "\"\"\"\n",
        "\n",
        "# Execute and load inference data\n",
        "inference_df = session.sql(inference_data_sql)\n",
        "inference_df.write.mode(\"overwrite\").save_as_table(\"ml_inference_logs\")\n",
        "\n",
        "# Verify data\n",
        "count_result = session.sql(\"SELECT COUNT(*) as count FROM ml_inference_logs\").collect()\n",
        "inference_count = count_result[0]['COUNT']\n",
        "\n",
        "print(f\"‚úÖ Generated {inference_count:,} inference records with ground truth\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nüìã Sample inference data:\")\n",
        "session.sql(\"SELECT * FROM ml_inference_logs LIMIT 5\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
