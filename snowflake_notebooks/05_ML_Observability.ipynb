{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Observability Suite\n",
        "\n",
        "This notebook demonstrates both:\n",
        "1. **Native Snowflake Model Registry Observability** - Using built-in monitoring features\n",
        "2. **Custom Observability Extensions** - Additional business-specific metrics and dashboards - Snowflake Native\n",
        "## Financial Services Model Monitoring & Drift Detection\n",
        "\n",
        "This notebook demonstrates Snowflake's ML Observability capabilities for production model monitoring.\n",
        "\n",
        "## What We'll Cover\n",
        "- Model performance monitoring with automatic drift detection\n",
        "- Data quality monitoring and alerting\n",
        "- Business impact tracking and ROI measurement\n",
        "- Production-ready monitoring dashboards\n",
        "\n",
        "## ML Observability Features\n",
        "- **Performance Tracking**: Accuracy, precision, recall, F1, AUC\n",
        "- **Drift Detection**: Feature drift, prediction drift, concept drift\n",
        "- **Data Quality**: Completeness, validity, consistency monitoring\n",
        "- **Alerting System**: Automated alerts for performance degradation\n",
        "- **Business Metrics**: Revenue impact, cost savings, ROI tracking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Leveraging Snowflake Model Registry Observability\n",
        "\n",
        "This notebook demonstrates how to use Snowflake's native Model Registry observability features alongside custom monitoring:\n",
        "\n",
        "### Native Features We Use:\n",
        "- **Model Metadata Tracking** - Version control and lineage through the Model Registry\n",
        "- **Model Tags** - Storing metrics and configuration as searchable tags\n",
        "- **Dynamic Tables** - Real-time monitoring of predictions\n",
        "- **Model Versioning** - Tracking model iterations and performance over time\n",
        "\n",
        "### Custom Extensions We Add:\n",
        "- **Business Impact Metrics** - ROI, revenue impact, churn prevention value\n",
        "- **Advanced Drift Detection** - Feature-level and prediction drift analysis\n",
        "- **Automated Alerts** - Custom thresholds and business rules\n",
        "- **Comprehensive Dashboards** - Unified view of model health and business value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import snowflake.snowpark as snowpark\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import *\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get active session\n",
        "session = get_active_session()\n",
        "\n",
        "print(f\"üèîÔ∏è Snowflake ML Observability Suite\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Set up database context\n",
        "try:\n",
        "    session.sql(\"USE DATABASE FINANCIAL_ML_DB\").collect()\n",
        "    session.sql(\"USE SCHEMA ML_PIPELINE\").collect()\n",
        "    print(f\"Database: FINANCIAL_ML_DB\")\n",
        "except:\n",
        "    # Use the Feature Store workaround database\n",
        "    session.sql(\"USE DATABASE FINANCIAL_ML_DEMO_20250923_093605\").collect()\n",
        "    session.sql(\"USE SCHEMA ML_PIPELINE\").collect()\n",
        "    print(f\"Database: FINANCIAL_ML_DEMO_20250923_093605\")\n",
        "\n",
        "print(f\"Schema: {session.get_current_schema()}\")\n",
        "print(f\"Warehouse: {session.get_current_warehouse()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.5: Native Model Registry Observability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use Snowflake's Native Model Registry Observability\n",
        "print(\"üîç Leveraging Snowflake Model Registry Observability...\")\n",
        "\n",
        "# Import model monitoring capabilities\n",
        "from snowflake.ml.registry import Registry\n",
        "from snowflake.ml.model import ModelVersion\n",
        "\n",
        "# Connect to the registry\n",
        "registry = Registry(session=session)\n",
        "\n",
        "# Get our registered model\n",
        "model = registry.get_model(\"CONVERSION_PREDICTOR\")\n",
        "model_version = model.default\n",
        "\n",
        "print(f\"‚úÖ Connected to model: {model.name} (version: {model_version.version_name})\")\n",
        "\n",
        "# Enable monitoring for the model\n",
        "print(\"\\nüìä Enabling Model Monitoring...\")\n",
        "\n",
        "# First, check what columns are available in the predictions view\n",
        "check_cols_sql = \"\"\"\n",
        "SELECT * FROM CLIENT_CONVERSION_PREDICTIONS LIMIT 1\n",
        "\"\"\"\n",
        "sample_df = session.sql(check_cols_sql).collect()\n",
        "if sample_df:\n",
        "    print(\"üìã Available columns in predictions view:\")\n",
        "    print(f\"   {list(sample_df[0].asDict().keys())}\")\n",
        "\n",
        "# Create a monitor for the model\n",
        "monitor_name = f\"{model.name}_MONITOR\"\n",
        "\n",
        "# Set up dynamic monitoring table with feature enrichment\n",
        "session.sql(f\"\"\"\n",
        "    CREATE OR REPLACE DYNAMIC TABLE {monitor_name}_PREDICTIONS\n",
        "    TARGET_LAG = '1 hour'\n",
        "    WAREHOUSE = {session.get_current_warehouse()}\n",
        "    AS\n",
        "    SELECT \n",
        "        cp.CLIENT_ID,\n",
        "        cp.CONVERSION_PROBABILITY,\n",
        "        cp.ACTUAL_CONVERSION,\n",
        "        -- Join with feature store to get feature values\n",
        "        fs.TOTAL_EVENTS_30D,\n",
        "        fs.ENGAGEMENT_SCORE_30D,\n",
        "        fs.DAYS_SINCE_LAST_ACTIVITY,\n",
        "        fs.ANNUAL_INCOME,\n",
        "        fs.CURRENT_401K_BALANCE,\n",
        "        fs.TOTAL_ASSETS_UNDER_MANAGEMENT,\n",
        "        -- Add monitoring metadata\n",
        "        CURRENT_TIMESTAMP() as MONITOR_TIMESTAMP,\n",
        "        DATE_TRUNC('hour', CURRENT_TIMESTAMP()) as MONITOR_HOUR,\n",
        "        -- Calculate prediction value (handle OBJECT type)\n",
        "        CAST(cp.CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) as PREDICTION_VALUE\n",
        "    FROM CLIENT_CONVERSION_PREDICTIONS cp\n",
        "    LEFT JOIN FEATURE_STORE fs ON cp.CLIENT_ID = fs.CLIENT_ID\n",
        "    WHERE cp.ACTUAL_CONVERSION IS NOT NULL  -- Only monitor records with ground truth\n",
        "\"\"\").collect()\n",
        "\n",
        "print(f\"‚úÖ Created dynamic monitoring table: {monitor_name}_PREDICTIONS\")\n",
        "\n",
        "# Create tags for ML observability (tags must exist before use)\n",
        "print(\"\\nüè∑Ô∏è Creating ML Observability Tags...\")\n",
        "\n",
        "tags_to_create = [\n",
        "    \"ML_OBSERVABILITY_ENABLED\",\n",
        "    \"MONITOR_TABLE\", \n",
        "    \"MONITORING_START_DATE\",\n",
        "    \"MODEL_TYPE\",\n",
        "    \"BUSINESS_DOMAIN\",\n",
        "    \"LATEST_ACCURACY\",\n",
        "    \"TOTAL_PREDICTIONS\",\n",
        "    \"POSITIVE_RATE\",\n",
        "    \"LAST_MONITORED\"\n",
        "]\n",
        "\n",
        "for tag_name in tags_to_create:\n",
        "    try:\n",
        "        session.sql(f\"\"\"\n",
        "            CREATE TAG IF NOT EXISTS {tag_name} \n",
        "            COMMENT = 'ML Model Observability Metadata'\n",
        "        \"\"\").collect()\n",
        "    except:\n",
        "        # Tag might already exist\n",
        "        pass\n",
        "\n",
        "print(\"‚úÖ Created observability tags\")\n",
        "\n",
        "# Apply tags to the model\n",
        "print(\"\\nüè∑Ô∏è Applying tags to model...\")\n",
        "\n",
        "# Set model tags for observability\n",
        "model.set_tag(\"ML_OBSERVABILITY_ENABLED\", \"true\")\n",
        "model.set_tag(\"MONITOR_TABLE\", f\"{monitor_name}_PREDICTIONS\")\n",
        "model.set_tag(\"MONITORING_START_DATE\", str(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
        "model.set_tag(\"MODEL_TYPE\", \"binary_classification\")\n",
        "model.set_tag(\"BUSINESS_DOMAIN\", \"financial_services\")\n",
        "\n",
        "print(\"‚úÖ Model monitoring enabled with tags\")\n",
        "\n",
        "# Create monitoring views for different metrics\n",
        "print(\"\\nüìä Creating Monitoring Views...\")\n",
        "\n",
        "# Performance monitoring view\n",
        "session.sql(f\"\"\"\n",
        "    CREATE OR REPLACE VIEW {monitor_name}_PERFORMANCE AS\n",
        "    WITH hourly_metrics AS (\n",
        "        SELECT \n",
        "            MONITOR_HOUR,\n",
        "            COUNT(*) as predictions_count,\n",
        "            AVG(CASE WHEN PREDICTION_VALUE = ACTUAL_CONVERSION THEN 1 ELSE 0 END) as accuracy,\n",
        "            AVG(CASE WHEN PREDICTION_VALUE = 1 AND ACTUAL_CONVERSION = 1 THEN 1\n",
        "                     WHEN PREDICTION_VALUE = 1 THEN 0 END) as precision,\n",
        "            AVG(CASE WHEN ACTUAL_CONVERSION = 1 AND PREDICTION_VALUE = 1 THEN 1\n",
        "                     WHEN ACTUAL_CONVERSION = 1 THEN 0 END) as recall\n",
        "        FROM {monitor_name}_PREDICTIONS\n",
        "        GROUP BY MONITOR_HOUR\n",
        "    )\n",
        "    SELECT \n",
        "        *,\n",
        "        2 * (precision * recall) / NULLIF(precision + recall, 0) as f1_score\n",
        "    FROM hourly_metrics\n",
        "    ORDER BY MONITOR_HOUR DESC\n",
        "\"\"\").collect()\n",
        "\n",
        "# Feature drift monitoring view\n",
        "session.sql(f\"\"\"\n",
        "    CREATE OR REPLACE VIEW {monitor_name}_FEATURE_DRIFT AS\n",
        "    WITH baseline_stats AS (\n",
        "        -- First 1000 predictions as baseline\n",
        "        SELECT \n",
        "            AVG(TOTAL_EVENTS_30D) as baseline_events_mean,\n",
        "            STDDEV(TOTAL_EVENTS_30D) as baseline_events_std,\n",
        "            AVG(ENGAGEMENT_SCORE_30D) as baseline_engagement_mean,\n",
        "            STDDEV(ENGAGEMENT_SCORE_30D) as baseline_engagement_std,\n",
        "            AVG(ANNUAL_INCOME) as baseline_income_mean,\n",
        "            STDDEV(ANNUAL_INCOME) as baseline_income_std\n",
        "        FROM (\n",
        "            SELECT * FROM {monitor_name}_PREDICTIONS \n",
        "            ORDER BY MONITOR_TIMESTAMP \n",
        "            LIMIT 1000\n",
        "        )\n",
        "    ),\n",
        "    current_window AS (\n",
        "        -- Most recent 1000 predictions\n",
        "        SELECT \n",
        "            AVG(TOTAL_EVENTS_30D) as current_events_mean,\n",
        "            AVG(ENGAGEMENT_SCORE_30D) as current_engagement_mean,\n",
        "            AVG(ANNUAL_INCOME) as current_income_mean\n",
        "        FROM (\n",
        "            SELECT * FROM {monitor_name}_PREDICTIONS \n",
        "            ORDER BY MONITOR_TIMESTAMP DESC \n",
        "            LIMIT 1000\n",
        "        )\n",
        "    )\n",
        "    SELECT \n",
        "        'TOTAL_EVENTS_30D' as feature_name,\n",
        "        baseline_events_mean as baseline_mean,\n",
        "        current_events_mean as current_mean,\n",
        "        ABS(current_events_mean - baseline_events_mean) / NULLIF(baseline_events_std, 0) as drift_score\n",
        "    FROM baseline_stats, current_window\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'ENGAGEMENT_SCORE_30D',\n",
        "        baseline_engagement_mean as baseline_mean,\n",
        "        current_engagement_mean as current_mean,\n",
        "        ABS(current_engagement_mean - baseline_engagement_mean) / NULLIF(baseline_engagement_std, 0)\n",
        "    FROM baseline_stats, current_window\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'ANNUAL_INCOME',\n",
        "        baseline_income_mean as baseline_mean,\n",
        "        current_income_mean as current_mean,\n",
        "        ABS(current_income_mean - baseline_income_mean) / NULLIF(baseline_income_std, 0)\n",
        "    FROM baseline_stats, current_window\n",
        "\"\"\").collect()\n",
        "\n",
        "print(f\"‚úÖ Created monitoring views:\")\n",
        "print(f\"   - {monitor_name}_PERFORMANCE (hourly performance metrics)\")\n",
        "print(f\"   - {monitor_name}_FEATURE_DRIFT (feature drift detection)\")\n",
        "\n",
        "# Log current model metrics\n",
        "print(\"\\nüìà Logging Current Model Metrics...\")\n",
        "\n",
        "# Get model version info\n",
        "version_info = {\n",
        "    \"name\": model.name,\n",
        "    \"version\": model_version.version_name,\n",
        "    \"model_ref\": str(model_version.model_ref) if hasattr(model_version, 'model_ref') else \"N/A\"\n",
        "}\n",
        "\n",
        "# Calculate and log performance metrics\n",
        "# First check if we have data in CLIENT_CONVERSION_PREDICTIONS\n",
        "check_data_sql = \"\"\"\n",
        "SELECT COUNT(*) as count FROM CLIENT_CONVERSION_PREDICTIONS WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "\"\"\"\n",
        "data_check = session.sql(check_data_sql).collect()\n",
        "has_data = data_check[0]['COUNT'] > 0\n",
        "\n",
        "if has_data:\n",
        "    # Use the source table directly for initial metrics\n",
        "    metrics_sql = \"\"\"\n",
        "    SELECT \n",
        "        COUNT(*) as total_predictions,\n",
        "        AVG(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = ACTUAL_CONVERSION \n",
        "            THEN 1 ELSE 0 \n",
        "        END) as accuracy,\n",
        "        COUNT(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 1 END) as positive_predictions,\n",
        "        COUNT(CASE WHEN ACTUAL_CONVERSION = 1 THEN 1 END) as actual_positives,\n",
        "        NULL as last_monitored\n",
        "    FROM CLIENT_CONVERSION_PREDICTIONS\n",
        "    WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "    \"\"\"\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No ground truth data available yet for metrics calculation\")\n",
        "    metrics_sql = None\n",
        "\n",
        "if metrics_sql:\n",
        "    metrics_df = session.sql(metrics_sql).collect()\n",
        "    if metrics_df:\n",
        "        metrics = metrics_df[0]\n",
        "        \n",
        "        # Set metrics as model tags for tracking\n",
        "        # Use float() to ensure proper type conversion and format with string formatting\n",
        "        model.set_tag(\"LATEST_ACCURACY\", f\"{float(metrics['ACCURACY']):.4f}\")\n",
        "        model.set_tag(\"TOTAL_PREDICTIONS\", str(int(metrics['TOTAL_PREDICTIONS'])))\n",
        "        model.set_tag(\"POSITIVE_RATE\", f\"{float(metrics['POSITIVE_PREDICTIONS']) / float(metrics['TOTAL_PREDICTIONS']):.4f}\")\n",
        "        if metrics['LAST_MONITORED']:\n",
        "            model.set_tag(\"LAST_MONITORED\", str(metrics['LAST_MONITORED']))\n",
        "        \n",
        "        print(f\"‚úÖ Model Metrics:\")\n",
        "        print(f\"   Total Predictions: {metrics['TOTAL_PREDICTIONS']:,}\")\n",
        "        print(f\"   Accuracy: {metrics['ACCURACY']:.2%}\")\n",
        "        print(f\"   Positive Predictions: {metrics['POSITIVE_PREDICTIONS']:,}\")\n",
        "        print(f\"   Actual Positives: {metrics['ACTUAL_POSITIVES']:,}\")\n",
        "        if metrics['LAST_MONITORED']:\n",
        "            print(f\"   Last Monitored: {metrics['LAST_MONITORED']}\")\n",
        "\n",
        "# Query performance trends (might be empty initially)\n",
        "try:\n",
        "    perf_trends = session.sql(f\"\"\"\n",
        "        SELECT * FROM {monitor_name}_PERFORMANCE \n",
        "        ORDER BY MONITOR_HOUR DESC \n",
        "        LIMIT 5\n",
        "    \"\"\").collect()\n",
        "    \n",
        "    if perf_trends:\n",
        "        print(\"\\nüìä Recent Performance Trends:\")\n",
        "        print(\"Hour                    | Predictions | Accuracy | Precision | Recall | F1\")\n",
        "        print(\"-\" * 75)\n",
        "        for row in perf_trends:\n",
        "            print(f\"{row['MONITOR_HOUR']} | {row['PREDICTIONS_COUNT']:>11,} | {row['ACCURACY']:>8.2%} | {row['PRECISION']:>9.2%} | {row['RECALL']:>6.2%} | {row['F1_SCORE']:>4.2f}\")\n",
        "    else:\n",
        "        print(\"\\nüìä Performance trends will be available after the dynamic table refreshes (1 hour)\")\n",
        "except:\n",
        "    print(\"\\nüìä Performance trends will be available after the dynamic table refreshes (1 hour)\")\n",
        "\n",
        "# Show all model tags\n",
        "print(\"\\nüè∑Ô∏è Model Tags (Observability Metadata):\")\n",
        "tags = model.show_tags()\n",
        "for tag_name, tag_value in tags.items():\n",
        "    print(f\"   {tag_name}: {tag_value}\")\n",
        "\n",
        "print(\"\\n‚úÖ Snowflake Native Model Registry Observability fully configured!\")\n",
        "print(\"üìä Monitor your model at:\")\n",
        "print(f\"   - Dynamic Table: {monitor_name}_PREDICTIONS\")\n",
        "print(f\"   - Performance View: {monitor_name}_PERFORMANCE\")\n",
        "print(f\"   - Drift View: {monitor_name}_FEATURE_DRIFT\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Continuing with additional custom observability features...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.6: Streamlit Model Monitoring Dashboard\n",
        "\n",
        "Interactive visualizations for real-time model observability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Streamlit Model Monitoring Dashboard\n",
        "print(\"üìä Creating Streamlit Model Monitoring Dashboard...\")\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Dashboard Title\n",
        "st.title(\"üéØ ML Model Observability Dashboard\")\n",
        "st.subheader(\"Financial Services - Conversion Prediction Model\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Get model info\n",
        "monitor_name = \"CONVERSION_PREDICTOR_MONITOR\"\n",
        "\n",
        "# Initialize shared variables\n",
        "available_cols = []\n",
        "drift_df = pd.DataFrame()\n",
        "\n",
        "# Create tabs for different monitoring aspects\n",
        "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"üìà Performance\", \"üîç Drift Analysis\", \"üí∞ Business Impact\", \"üö® Alerts\", \"üè∑Ô∏è Model Info\"])\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"Model Performance Metrics\")\n",
        "    \n",
        "    # Performance over time\n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        # Check if performance view exists first\n",
        "        try:\n",
        "            check_perf_view = f\"\"\"\n",
        "            SHOW VIEWS LIKE '{monitor_name}_PERFORMANCE' IN SCHEMA {session.get_current_schema()}\n",
        "            \"\"\"\n",
        "            perf_view_exists = len(session.sql(check_perf_view).collect()) > 0\n",
        "            \n",
        "            if perf_view_exists:\n",
        "                # Get performance metrics\n",
        "                perf_sql = f\"\"\"\n",
        "                SELECT \n",
        "                    MONITOR_HOUR,\n",
        "                    ACCURACY,\n",
        "                    PRECISION,\n",
        "                    RECALL,\n",
        "                    F1_SCORE,\n",
        "                    PREDICTIONS_COUNT\n",
        "                FROM {monitor_name}_PERFORMANCE\n",
        "                ORDER BY MONITOR_HOUR DESC\n",
        "                LIMIT 24  -- Last 24 hours\n",
        "                \"\"\"\n",
        "                \n",
        "                perf_df = session.sql(perf_sql).to_pandas()\n",
        "            else:\n",
        "                perf_df = pd.DataFrame()  # Empty dataframe\n",
        "        except:\n",
        "            perf_df = pd.DataFrame()  # Empty dataframe on any error\n",
        "        \n",
        "        if not perf_df.empty:\n",
        "            # Performance metrics over time\n",
        "            fig_perf = go.Figure()\n",
        "            fig_perf.add_trace(go.Scatter(x=perf_df['MONITOR_HOUR'], y=perf_df['ACCURACY'], \n",
        "                                          mode='lines+markers', name='Accuracy', line=dict(color='blue')))\n",
        "            fig_perf.add_trace(go.Scatter(x=perf_df['MONITOR_HOUR'], y=perf_df['PRECISION'], \n",
        "                                          mode='lines+markers', name='Precision', line=dict(color='green')))\n",
        "            fig_perf.add_trace(go.Scatter(x=perf_df['MONITOR_HOUR'], y=perf_df['RECALL'], \n",
        "                                          mode='lines+markers', name='Recall', line=dict(color='orange')))\n",
        "            fig_perf.add_trace(go.Scatter(x=perf_df['MONITOR_HOUR'], y=perf_df['F1_SCORE'], \n",
        "                                          mode='lines+markers', name='F1 Score', line=dict(color='red')))\n",
        "            \n",
        "            fig_perf.update_layout(\n",
        "                title='Model Performance Over Time',\n",
        "                xaxis_title='Time',\n",
        "                yaxis_title='Score',\n",
        "                yaxis=dict(range=[0, 1]),\n",
        "                height=400\n",
        "            )\n",
        "            st.plotly_chart(fig_perf, use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"Performance data will be available after the monitoring table refreshes (1 hour)\")\n",
        "    \n",
        "    with col2:\n",
        "        # Current metrics display\n",
        "        st.subheader(\"Current Performance\")\n",
        "        \n",
        "        current_metrics_sql = \"\"\"\n",
        "        SELECT \n",
        "            AVG(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = ACTUAL_CONVERSION THEN 1 ELSE 0 END) as accuracy,\n",
        "            COUNT(*) as total_predictions,\n",
        "            COUNT(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 1 END) as positive_predictions\n",
        "        FROM CLIENT_CONVERSION_PREDICTIONS\n",
        "        WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "        \"\"\"\n",
        "        \n",
        "        current_metrics = session.sql(current_metrics_sql).collect()[0]\n",
        "        \n",
        "        # Display metrics\n",
        "        metric_col1, metric_col2, metric_col3 = st.columns(3)\n",
        "        with metric_col1:\n",
        "            st.metric(\"Accuracy\", f\"{float(current_metrics['ACCURACY']):.2%}\")\n",
        "        with metric_col2:\n",
        "            st.metric(\"Total Predictions\", f\"{int(current_metrics['TOTAL_PREDICTIONS']):,}\")\n",
        "        with metric_col3:\n",
        "            positive_rate = float(current_metrics['POSITIVE_PREDICTIONS']) / float(current_metrics['TOTAL_PREDICTIONS'])\n",
        "            st.metric(\"Positive Rate\", f\"{positive_rate:.2%}\")\n",
        "        \n",
        "        # Confusion Matrix\n",
        "        st.subheader(\"Confusion Matrix\")\n",
        "        cm_sql = \"\"\"\n",
        "        SELECT \n",
        "            SUM(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 AND ACTUAL_CONVERSION = 1 THEN 1 ELSE 0 END) as TP,\n",
        "            SUM(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 AND ACTUAL_CONVERSION = 0 THEN 1 ELSE 0 END) as FP,\n",
        "            SUM(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 0 AND ACTUAL_CONVERSION = 0 THEN 1 ELSE 0 END) as TN,\n",
        "            SUM(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 0 AND ACTUAL_CONVERSION = 1 THEN 1 ELSE 0 END) as FN\n",
        "        FROM CLIENT_CONVERSION_PREDICTIONS\n",
        "        WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "        \"\"\"\n",
        "        cm_data = session.sql(cm_sql).collect()[0]\n",
        "        \n",
        "        cm_matrix = [[int(cm_data['TN']), int(cm_data['FP'])], \n",
        "                     [int(cm_data['FN']), int(cm_data['TP'])]]\n",
        "        \n",
        "        fig_cm = px.imshow(cm_matrix, \n",
        "                          labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
        "                          x=['No Conversion', 'Conversion'],\n",
        "                          y=['No Conversion', 'Conversion'],\n",
        "                          text_auto=True,\n",
        "                          color_continuous_scale='Blues')\n",
        "        fig_cm.update_layout(title='Confusion Matrix', height=300)\n",
        "        st.plotly_chart(fig_cm, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"Feature Drift Analysis\")\n",
        "    \n",
        "    # Check if drift monitoring view exists\n",
        "    try:\n",
        "        # First check if the view exists\n",
        "        check_view_sql = f\"\"\"\n",
        "        SHOW VIEWS LIKE '{monitor_name}_FEATURE_DRIFT' IN SCHEMA {session.get_current_schema()}\n",
        "        \"\"\"\n",
        "        view_exists = len(session.sql(check_view_sql).collect()) > 0\n",
        "        \n",
        "        if not view_exists:\n",
        "            st.info(\"üîÑ Feature drift monitoring is being set up. The dynamic table will refresh in approximately 1 hour.\")\n",
        "            \n",
        "            # Show sample drift analysis with mock data for demo purposes\n",
        "            st.subheader(\"Sample Drift Analysis (Demo Data)\")\n",
        "            \n",
        "            # Create sample drift data\n",
        "            sample_features = ['TOTAL_EVENTS_30D', 'ENGAGEMENT_SCORE_30D', 'ANNUAL_INCOME']\n",
        "            sample_drift_scores = [0.5, 1.3, 0.8]\n",
        "            sample_baseline = [15.2, 0.65, 75000]\n",
        "            sample_current = [14.8, 0.71, 73500]\n",
        "            \n",
        "            fig_sample = go.Figure()\n",
        "            fig_sample.add_trace(go.Bar(\n",
        "                x=sample_features,\n",
        "                y=sample_drift_scores,\n",
        "                marker_color=['green', 'orange', 'green'],\n",
        "                text=[f\"{score:.2f}\" for score in sample_drift_scores],\n",
        "                textposition='auto'\n",
        "            ))\n",
        "            \n",
        "            fig_sample.update_layout(\n",
        "                title='Sample Feature Drift Scores (Demo)',\n",
        "                xaxis_title='Feature',\n",
        "                yaxis_title='Drift Score',\n",
        "                height=400\n",
        "            )\n",
        "            \n",
        "            # Add threshold lines\n",
        "            fig_sample.add_hline(y=1, line_dash=\"dash\", line_color=\"orange\", \n",
        "                               annotation_text=\"Warning Threshold\")\n",
        "            fig_sample.add_hline(y=2, line_dash=\"dash\", line_color=\"red\", \n",
        "                               annotation_text=\"Alert Threshold\")\n",
        "            \n",
        "            st.plotly_chart(fig_sample, use_container_width=True)\n",
        "            \n",
        "            st.caption(\"‚è±Ô∏è Real drift analysis will be available once the monitoring table refreshes.\")\n",
        "        else:\n",
        "            # Get drift data\n",
        "            drift_sql = f\"\"\"\n",
        "            SELECT \n",
        "                FEATURE_NAME,\n",
        "                BASELINE_MEAN,\n",
        "                CURRENT_MEAN,\n",
        "                DRIFT_SCORE\n",
        "            FROM {monitor_name}_FEATURE_DRIFT\n",
        "            \"\"\"\n",
        "            \n",
        "            drift_df = session.sql(drift_sql).to_pandas()\n",
        "            \n",
        "            if not drift_df.empty:\n",
        "                # Drift visualization\n",
        "                fig_drift = go.Figure()\n",
        "                fig_drift.add_trace(go.Bar(\n",
        "                    x=drift_df['FEATURE_NAME'],\n",
        "                    y=drift_df['DRIFT_SCORE'],\n",
        "                    marker_color=['red' if score > 2 else 'orange' if score > 1 else 'green' \n",
        "                                 for score in drift_df['DRIFT_SCORE']],\n",
        "                    text=[f\"{score:.2f}\" for score in drift_df['DRIFT_SCORE']],\n",
        "                    textposition='auto'\n",
        "                ))\n",
        "                \n",
        "                fig_drift.update_layout(\n",
        "                    title='Feature Drift Scores',\n",
        "                    xaxis_title='Feature',\n",
        "                    yaxis_title='Drift Score',\n",
        "                    height=400\n",
        "                )\n",
        "                \n",
        "                # Add threshold lines\n",
        "                fig_drift.add_hline(y=1, line_dash=\"dash\", line_color=\"orange\", \n",
        "                                   annotation_text=\"Warning Threshold\")\n",
        "                fig_drift.add_hline(y=2, line_dash=\"dash\", line_color=\"red\", \n",
        "                                   annotation_text=\"Alert Threshold\")\n",
        "                \n",
        "                st.plotly_chart(fig_drift, use_container_width=True)\n",
        "                \n",
        "                # Feature comparison\n",
        "                st.subheader(\"Feature Distribution Comparison\")\n",
        "                for _, row in drift_df.iterrows():\n",
        "                    with st.expander(f\"{row['FEATURE_NAME']} Details\"):\n",
        "                        col1, col2, col3 = st.columns(3)\n",
        "                        with col1:\n",
        "                            st.metric(\"Baseline Mean\", f\"{row['BASELINE_MEAN']:.2f}\")\n",
        "                        with col2:\n",
        "                            st.metric(\"Current Mean\", f\"{row['CURRENT_MEAN']:.2f}\")\n",
        "                        with col3:\n",
        "                            st.metric(\"Drift Score\", f\"{row['DRIFT_SCORE']:.2f}\",\n",
        "                                     delta=f\"{row['DRIFT_SCORE']:.2f}\",\n",
        "                                     delta_color=\"inverse\")\n",
        "            else:\n",
        "                st.info(\"üìä Drift analysis is initializing. Data will populate after the first monitoring cycle completes.\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"‚ö†Ô∏è Drift monitoring setup in progress. This feature will be available shortly.\")\n",
        "        if st.checkbox(\"Show technical details\"):\n",
        "            st.code(str(e))\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"Business Impact Analysis\")\n",
        "    \n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        # Conversion Impact\n",
        "        # First check what columns exist in CLIENT_SEGMENTS_BATCH\n",
        "        try:\n",
        "            check_cols = session.sql(\"SELECT * FROM CLIENT_SEGMENTS_BATCH LIMIT 1\").collect()\n",
        "            if check_cols:\n",
        "                available_cols = list(check_cols[0].asDict().keys())\n",
        "                # Debug: Show available columns in console\n",
        "                print(f\"DEBUG: Available columns in CLIENT_SEGMENTS_BATCH: {available_cols}\")\n",
        "                # Also show in UI for transparency\n",
        "                with st.expander(\"Debug Info - Available Columns\"):\n",
        "                    st.write(f\"CLIENT_SEGMENTS_BATCH columns: {available_cols}\")\n",
        "        except Exception as e:\n",
        "            st.error(\"CLIENT_SEGMENTS_BATCH table not found. Please run the Inference notebook first.\")\n",
        "            print(f\"DEBUG: Error accessing CLIENT_SEGMENTS_BATCH: {str(e)}\")\n",
        "            available_cols = []\n",
        "        \n",
        "        if available_cols:\n",
        "            # Dynamically check for available columns and adjust query\n",
        "            if 'SEGMENT' in available_cols:\n",
        "                segment_col = 'SEGMENT'\n",
        "                high_value = \"'High Value'\"\n",
        "            elif 'PRIORITY_TIER' in available_cols:\n",
        "                segment_col = 'PRIORITY_TIER'\n",
        "                high_value = \"'Tier 1'\"\n",
        "            else:\n",
        "                segment_col = None\n",
        "            \n",
        "            if segment_col:\n",
        "                conversion_sql = f\"\"\"\n",
        "                SELECT \n",
        "                    COUNT(DISTINCT CLIENT_ID) as total_clients,\n",
        "                    COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) as predicted_conversions,\n",
        "                    COUNT(CASE WHEN {segment_col} = {high_value} THEN 1 END) as high_priority_clients,\n",
        "                    AVG(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 ELSE 0 END) as conversion_rate\n",
        "                FROM CLIENT_SEGMENTS_BATCH\n",
        "                \"\"\"\n",
        "            else:\n",
        "                # No segment column found, use basic metrics\n",
        "                conversion_sql = \"\"\"\n",
        "                SELECT \n",
        "                    COUNT(DISTINCT CLIENT_ID) as total_clients,\n",
        "                    COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) as predicted_conversions,\n",
        "                    COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) as high_priority_clients,\n",
        "                    AVG(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 ELSE 0 END) as conversion_rate\n",
        "                FROM CLIENT_SEGMENTS_BATCH\n",
        "                \"\"\"\n",
        "            \n",
        "            conv_metrics = session.sql(conversion_sql).collect()[0]\n",
        "        else:\n",
        "            # Use CLIENT_CONVERSION_PREDICTIONS as fallback\n",
        "            conversion_sql = \"\"\"\n",
        "            SELECT \n",
        "                COUNT(DISTINCT CLIENT_ID) as total_clients,\n",
        "                COUNT(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 1 END) as predicted_conversions,\n",
        "                COUNT(CASE WHEN BUSINESS_PRIORITY_SCORE > 0.8 THEN 1 END) as high_priority_clients,\n",
        "                AVG(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 1 ELSE 0 END) as conversion_rate\n",
        "            FROM CLIENT_CONVERSION_PREDICTIONS\n",
        "            WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "            \"\"\"\n",
        "            \n",
        "            conv_metrics = session.sql(conversion_sql).collect()[0]\n",
        "        \n",
        "        st.subheader(\"Conversion Metrics\")\n",
        "        st.metric(\"Total Clients Analyzed\", f\"{int(conv_metrics['TOTAL_CLIENTS']):,}\")\n",
        "        st.metric(\"Predicted Conversions\", f\"{int(conv_metrics['PREDICTED_CONVERSIONS']):,}\")\n",
        "        st.metric(\"High Priority Clients\", f\"{int(conv_metrics['HIGH_PRIORITY_CLIENTS']):,}\")\n",
        "        st.metric(\"Conversion Rate\", f\"{float(conv_metrics['CONVERSION_RATE']):.2%}\")\n",
        "    \n",
        "    with col2:\n",
        "        # Churn Prevention\n",
        "        try:\n",
        "            churn_sql = \"\"\"\n",
        "            SELECT \n",
        "                COUNT(*) as at_risk_clients,\n",
        "                COUNT(CASE WHEN VALUE_TIER = 'High' THEN 1 END) as high_value_at_risk,\n",
        "                AVG(CHURN_RISK_SCORE) as avg_churn_risk\n",
        "            FROM CLIENT_CHURN_SEGMENTS\n",
        "            WHERE CHURN_RISK_SCORE > 0.6\n",
        "            \"\"\"\n",
        "            \n",
        "            churn_metrics = session.sql(churn_sql).collect()[0]\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG: Error accessing CLIENT_CHURN_SEGMENTS: {str(e)}\")\n",
        "            # Use default values if churn table doesn't exist\n",
        "            churn_metrics = {\n",
        "                'AT_RISK_CLIENTS': 0,\n",
        "                'HIGH_VALUE_AT_RISK': 0,\n",
        "                'AVG_CHURN_RISK': 0.0\n",
        "            }\n",
        "        \n",
        "        st.subheader(\"Churn Prevention\")\n",
        "        st.metric(\"At-Risk Clients\", f\"{int(churn_metrics['AT_RISK_CLIENTS']):,}\")\n",
        "        st.metric(\"High Value at Risk\", f\"{int(churn_metrics['HIGH_VALUE_AT_RISK']):,}\")\n",
        "        st.metric(\"Avg Churn Risk\", f\"{float(churn_metrics['AVG_CHURN_RISK']):.2%}\")\n",
        "    \n",
        "    # Revenue Impact Chart\n",
        "    st.subheader(\"Revenue Impact Projection\")\n",
        "    \n",
        "    if available_cols:\n",
        "        # Check which grouping column is available\n",
        "        if 'SEGMENT' in available_cols:\n",
        "            group_col = 'SEGMENT'\n",
        "            title_text = 'Client Distribution by Segment'\n",
        "        elif 'PRIORITY_TIER' in available_cols:\n",
        "            group_col = 'PRIORITY_TIER'\n",
        "            title_text = 'Client Distribution by Priority Tier'\n",
        "        else:\n",
        "            group_col = None\n",
        "        \n",
        "        if group_col:\n",
        "            revenue_sql = f\"\"\"\n",
        "            WITH revenue_calc AS (\n",
        "                SELECT \n",
        "                    {group_col},\n",
        "                    COUNT(*) as client_count,\n",
        "                    AVG(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 50000 ELSE 0 END) as avg_revenue_per_group\n",
        "                FROM CLIENT_SEGMENTS_BATCH\n",
        "                GROUP BY {group_col}\n",
        "            )\n",
        "            SELECT * FROM revenue_calc ORDER BY avg_revenue_per_group DESC\n",
        "            \"\"\"\n",
        "            \n",
        "            revenue_df = session.sql(revenue_sql).to_pandas()\n",
        "            \n",
        "            fig_revenue = px.bar(revenue_df, x=group_col, y='CLIENT_COUNT', \n",
        "                                color='AVG_REVENUE_PER_GROUP',\n",
        "                                title=title_text,\n",
        "                                labels={'CLIENT_COUNT': 'Number of Clients',\n",
        "                                       'AVG_REVENUE_PER_GROUP': 'Potential Revenue'})\n",
        "        else:\n",
        "            # Fallback to grouping by conversion probability\n",
        "            revenue_sql = \"\"\"\n",
        "            WITH revenue_calc AS (\n",
        "                SELECT \n",
        "                    CASE \n",
        "                        WHEN CONVERSION_PROBABILITY = 1 THEN 'High Conversion'\n",
        "                        ELSE 'Low Conversion'\n",
        "                    END as conversion_group,\n",
        "                    COUNT(*) as client_count,\n",
        "                    AVG(CONVERSION_PROBABILITY) as avg_conversion_rate\n",
        "                FROM CLIENT_SEGMENTS_BATCH\n",
        "                GROUP BY conversion_group\n",
        "            )\n",
        "            SELECT * FROM revenue_calc ORDER BY avg_conversion_rate DESC\n",
        "            \"\"\"\n",
        "            \n",
        "            revenue_df = session.sql(revenue_sql).to_pandas()\n",
        "            \n",
        "            fig_revenue = px.bar(revenue_df, x='CONVERSION_GROUP', y='CLIENT_COUNT', \n",
        "                                color='AVG_CONVERSION_RATE',\n",
        "                                title='Client Distribution by Conversion Likelihood',\n",
        "                                labels={'CLIENT_COUNT': 'Number of Clients',\n",
        "                                       'AVG_CONVERSION_RATE': 'Conversion Rate'})\n",
        "    else:\n",
        "        # Fallback to CLIENT_CONVERSION_PREDICTIONS\n",
        "        revenue_sql = \"\"\"\n",
        "        WITH revenue_calc AS (\n",
        "            SELECT \n",
        "                CASE \n",
        "                    WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 'High Conversion'\n",
        "                    ELSE 'Low Conversion'\n",
        "                END as conversion_group,\n",
        "                COUNT(*) as client_count,\n",
        "                AVG(BUSINESS_PRIORITY_SCORE) as avg_priority_score\n",
        "            FROM CLIENT_CONVERSION_PREDICTIONS\n",
        "            WHERE ACTUAL_CONVERSION IS NOT NULL\n",
        "            GROUP BY conversion_group\n",
        "        )\n",
        "        SELECT * FROM revenue_calc ORDER BY avg_priority_score DESC\n",
        "        \"\"\"\n",
        "        \n",
        "        revenue_df = session.sql(revenue_sql).to_pandas()\n",
        "        \n",
        "        fig_revenue = px.bar(revenue_df, x='CONVERSION_GROUP', y='CLIENT_COUNT', \n",
        "                            color='AVG_PRIORITY_SCORE',\n",
        "                            title='Client Distribution by Conversion Likelihood',\n",
        "                            labels={'CLIENT_COUNT': 'Number of Clients',\n",
        "                                   'AVG_PRIORITY_SCORE': 'Business Priority'})\n",
        "    \n",
        "    st.plotly_chart(fig_revenue, use_container_width=True)\n",
        "\n",
        "with tab4:\n",
        "    st.header(\"Monitoring Alerts\")\n",
        "    \n",
        "    # Define alert thresholds\n",
        "    alert_thresholds = {\n",
        "        'accuracy': 0.65,\n",
        "        'drift': 2.0,\n",
        "        'prediction_volume': 100\n",
        "    }\n",
        "    \n",
        "    # Check current status\n",
        "    alerts = []\n",
        "    \n",
        "    # Performance alerts\n",
        "    if float(current_metrics['ACCURACY']) < alert_thresholds['accuracy']:\n",
        "        alerts.append({\n",
        "            'type': 'Performance',\n",
        "            'severity': 'High',\n",
        "            'message': f\"Model accuracy ({float(current_metrics['ACCURACY']):.2%}) below threshold ({alert_thresholds['accuracy']:.0%})\",\n",
        "            'action': 'Consider model retraining'\n",
        "        })\n",
        "    \n",
        "    # Drift alerts\n",
        "    if not drift_df.empty:\n",
        "        try:\n",
        "            high_drift = drift_df[drift_df['DRIFT_SCORE'] > alert_thresholds['drift']]\n",
        "            for _, feature in high_drift.iterrows():\n",
        "                alerts.append({\n",
        "                    'type': 'Drift',\n",
        "                    'severity': 'Medium',\n",
        "                    'message': f\"High drift detected in {feature['FEATURE_NAME']} (score: {feature['DRIFT_SCORE']:.2f})\",\n",
        "                    'action': 'Investigate feature distribution changes'\n",
        "                })\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Display alerts\n",
        "    if alerts:\n",
        "        for alert in alerts:\n",
        "            if alert['severity'] == 'High':\n",
        "                st.error(f\"üö® **{alert['type']} Alert**: {alert['message']}\")\n",
        "            else:\n",
        "                st.warning(f\"‚ö†Ô∏è **{alert['type']} Alert**: {alert['message']}\")\n",
        "            st.caption(f\"Recommended Action: {alert['action']}\")\n",
        "    else:\n",
        "        st.success(\"‚úÖ All systems operating normally\")\n",
        "    \n",
        "    # Alert History\n",
        "    st.subheader(\"Alert History\")\n",
        "    alert_history_sql = \"\"\"\n",
        "    SELECT \n",
        "        MONITORING_TIMESTAMP,\n",
        "        FEATURE_NAME,\n",
        "        DRIFT_SCORE,\n",
        "        ALERT_TRIGGERED\n",
        "    FROM DATA_DRIFT_MONITORING\n",
        "    WHERE ALERT_TRIGGERED = TRUE\n",
        "    ORDER BY MONITORING_TIMESTAMP DESC\n",
        "    LIMIT 10\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        alert_history_df = session.sql(alert_history_sql).to_pandas()\n",
        "        if not alert_history_df.empty:\n",
        "            st.dataframe(alert_history_df, use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"No historical alerts found\")\n",
        "    except:\n",
        "        st.info(\"Alert history will be available as monitoring progresses\")\n",
        "\n",
        "with tab5:\n",
        "    st.header(\"Model Information & Tags\")\n",
        "    \n",
        "    # Get model from registry\n",
        "    try:\n",
        "        from snowflake.ml.registry import Registry\n",
        "        registry = Registry(session)\n",
        "        model = registry.get_model(\"CONVERSION_PREDICTOR\")\n",
        "        model_version = model.version(\"V1\")\n",
        "        model_tags = model.show_tags()\n",
        "    except:\n",
        "        # Fallback - read tags from MODEL_DEPLOYMENT_METADATA\n",
        "        try:\n",
        "            tags_sql = \"\"\"\n",
        "            SELECT TAG_NAME, TAG_VALUE \n",
        "            FROM MODEL_DEPLOYMENT_METADATA \n",
        "            WHERE MODEL_NAME = 'CONVERSION_PREDICTOR'\n",
        "            \"\"\"\n",
        "            tags_df = session.sql(tags_sql).to_pandas()\n",
        "            model_tags = dict(zip(tags_df['TAG_NAME'], tags_df['TAG_VALUE']))\n",
        "            model_version = type('obj', (object,), {'version_name': 'V1'})()\n",
        "        except:\n",
        "            model_tags = {\n",
        "                'ML_OBSERVABILITY_ENABLED': 'TRUE',\n",
        "                'MODEL_TYPE': 'BINARY_CLASSIFICATION',\n",
        "                'BUSINESS_DOMAIN': 'FINANCIAL_SERVICES'\n",
        "            }\n",
        "            model_version = type('obj', (object,), {'version_name': 'V1'})()\n",
        "    \n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        st.subheader(\"Model Metadata\")\n",
        "        for tag_name, tag_value in model_tags.items():\n",
        "            if tag_name in ['ML_OBSERVABILITY_ENABLED', 'MODEL_TYPE', 'BUSINESS_DOMAIN']:\n",
        "                st.text(f\"{tag_name}: {tag_value}\")\n",
        "    \n",
        "    with col2:\n",
        "        st.subheader(\"Latest Metrics\")\n",
        "        for tag_name, tag_value in model_tags.items():\n",
        "            if tag_name in ['LATEST_ACCURACY', 'TOTAL_PREDICTIONS', 'POSITIVE_RATE', 'LAST_MONITORED']:\n",
        "                st.text(f\"{tag_name}: {tag_value}\")\n",
        "    \n",
        "    # Model version info\n",
        "    st.subheader(\"Model Version Details\")\n",
        "    if hasattr(model, 'name'):\n",
        "        st.text(f\"Model Name: {model.name}\")\n",
        "    else:\n",
        "        st.text(f\"Model Name: CONVERSION_PREDICTOR\")\n",
        "    st.text(f\"Current Version: {model_version.version_name}\")\n",
        "    st.text(f\"Monitor Table: {monitor_name}_PREDICTIONS\")\n",
        "    \n",
        "    # Monitoring Configuration\n",
        "    st.subheader(\"Monitoring Configuration\")\n",
        "    st.text(f\"Dynamic Table Refresh: Every 1 hour\")\n",
        "    st.text(f\"Performance View: {monitor_name}_PERFORMANCE\")\n",
        "    st.text(f\"Drift View: {monitor_name}_FEATURE_DRIFT\")\n",
        "\n",
        "# Add refresh button\n",
        "if st.button(\"üîÑ Refresh Dashboard\"):\n",
        "    st.rerun()\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Dashboard auto-refreshes every 60 seconds\")\n",
        "\n",
        "# Auto-refresh every 60 seconds\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <script>\n",
        "        setTimeout(function(){\n",
        "            window.location.reload();\n",
        "        }, 60000);\n",
        "    </script>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Streamlit Model Monitoring Dashboard created!\")\n",
        "print(\"üìä The dashboard provides real-time visualization of:\")\n",
        "print(\"   - Model performance metrics over time\")\n",
        "print(\"   - Feature drift analysis\")\n",
        "print(\"   - Business impact metrics\")\n",
        "print(\"   - Monitoring alerts\")\n",
        "print(\"   - Model metadata and tags\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Custom ML Observability Infrastructure\n",
        "\n",
        "Building on native capabilities with custom monitoring tables for business-specific metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check and use existing ML Observability infrastructure\n",
        "print(\"üõ†Ô∏è Checking ML Observability infrastructure...\")\n",
        "\n",
        "# Check for existing monitoring tables from notebook 4\n",
        "existing_tables = []\n",
        "try:\n",
        "    session.sql(\"SELECT * FROM PREDICTION_MONITORING LIMIT 1\").collect()\n",
        "    existing_tables.append(\"PREDICTION_MONITORING\")\n",
        "    print(\"‚úÖ Found existing PREDICTION_MONITORING table\")\n",
        "except:\n",
        "    print(\"‚ùå PREDICTION_MONITORING table not found\")\n",
        "\n",
        "try:\n",
        "    session.sql(\"SELECT * FROM MODEL_PERFORMANCE_TRACKING LIMIT 1\").collect()\n",
        "    existing_tables.append(\"MODEL_PERFORMANCE_TRACKING\")\n",
        "    print(\"‚úÖ Found existing MODEL_PERFORMANCE_TRACKING table\")\n",
        "except:\n",
        "    print(\"‚ùå MODEL_PERFORMANCE_TRACKING table not found\")\n",
        "\n",
        "try:\n",
        "    session.sql(\"SELECT * FROM DATA_DRIFT_MONITORING LIMIT 1\").collect()\n",
        "    existing_tables.append(\"DATA_DRIFT_MONITORING\")\n",
        "    print(\"‚úÖ Found existing DATA_DRIFT_MONITORING table\")\n",
        "except:\n",
        "    print(\"‚ùå DATA_DRIFT_MONITORING table not found\")\n",
        "\n",
        "# Create business impact tracking table (new for observability)\n",
        "business_impact_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ML_BUSINESS_IMPACT (\n",
        "    impact_id NUMBER AUTOINCREMENT,\n",
        "    evaluation_date DATE,\n",
        "    model_name VARCHAR,\n",
        "    model_version VARCHAR,\n",
        "    -- Conversion metrics\n",
        "    total_conversions INTEGER,\n",
        "    conversion_rate FLOAT,\n",
        "    revenue_generated FLOAT,\n",
        "    -- Churn metrics\n",
        "    churns_prevented INTEGER,\n",
        "    retention_rate FLOAT,\n",
        "    revenue_retained FLOAT,\n",
        "    -- Overall impact\n",
        "    total_business_value FLOAT,\n",
        "    roi_percentage FLOAT\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(business_impact_sql).collect()\n",
        "print(\"‚úÖ Created ML_BUSINESS_IMPACT table\")\n",
        "\n",
        "# Create model comparison table\n",
        "comparison_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ML_MODEL_COMPARISON (\n",
        "    comparison_id NUMBER AUTOINCREMENT,\n",
        "    comparison_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),\n",
        "    model_a_name VARCHAR,\n",
        "    model_a_version VARCHAR,\n",
        "    model_a_accuracy FLOAT,\n",
        "    model_b_name VARCHAR,\n",
        "    model_b_version VARCHAR,\n",
        "    model_b_accuracy FLOAT,\n",
        "    performance_difference FLOAT,\n",
        "    recommendation VARCHAR\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "session.sql(comparison_sql).collect()\n",
        "print(\"‚úÖ Created ML_MODEL_COMPARISON table\")\n",
        "\n",
        "print(f\"\\nüéØ ML Observability infrastructure ready!\")\n",
        "print(f\"   Using {len(existing_tables)} existing monitoring tables\")\n",
        "print(f\"   Added 2 new observability tables\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Analyze Production Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze production model performance using real data\n",
        "print(\"üìä Analyzing production model performance...\")\n",
        "\n",
        "# Get current model performance metrics\n",
        "performance_sql = \"\"\"\n",
        "WITH prediction_analysis AS (\n",
        "    SELECT \n",
        "        'CONVERSION_PREDICTOR' as model_name,\n",
        "        'V1' as model_version,\n",
        "        COUNT(*) as total_predictions,\n",
        "        -- Extract binary predictions from OBJECT\n",
        "        SUM(CASE WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 THEN 1 ELSE 0 END) as predicted_conversions,\n",
        "        SUM(CASE WHEN ACTUAL_CONVERSION = 1 THEN 1 ELSE 0 END) as actual_conversions,\n",
        "        \n",
        "        -- Calculate metrics\n",
        "        COUNT(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = ACTUAL_CONVERSION \n",
        "            THEN 1 \n",
        "        END) / NULLIF(COUNT(*), 0) as accuracy,\n",
        "        \n",
        "        -- True Positives, False Positives, etc.\n",
        "        SUM(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 \n",
        "            AND ACTUAL_CONVERSION = 1 THEN 1 ELSE 0 \n",
        "        END) as true_positives,\n",
        "        \n",
        "        SUM(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 1 \n",
        "            AND ACTUAL_CONVERSION = 0 THEN 1 ELSE 0 \n",
        "        END) as false_positives,\n",
        "        \n",
        "        SUM(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 0 \n",
        "            AND ACTUAL_CONVERSION = 0 THEN 1 ELSE 0 \n",
        "        END) as true_negatives,\n",
        "        \n",
        "        SUM(CASE \n",
        "            WHEN CAST(CONVERSION_PROBABILITY:\"PREDICTION\" AS FLOAT) = 0 \n",
        "            AND ACTUAL_CONVERSION = 1 THEN 1 ELSE 0 \n",
        "        END) as false_negatives\n",
        "        \n",
        "    FROM CLIENT_CONVERSION_PREDICTIONS\n",
        ")\n",
        "SELECT \n",
        "    model_name,\n",
        "    model_version,\n",
        "    total_predictions,\n",
        "    predicted_conversions,\n",
        "    actual_conversions,\n",
        "    accuracy,\n",
        "    true_positives / NULLIF(true_positives + false_positives, 0) as precision,\n",
        "    true_positives / NULLIF(true_positives + false_negatives, 0) as recall,\n",
        "    2 * (precision * recall) / NULLIF(precision + recall, 0) as f1_score,\n",
        "    true_positives,\n",
        "    false_positives,\n",
        "    true_negatives,\n",
        "    false_negatives\n",
        "FROM prediction_analysis\n",
        "\"\"\"\n",
        "\n",
        "performance_df = session.sql(performance_sql).collect()\n",
        "\n",
        "if performance_df:\n",
        "    perf = performance_df[0]\n",
        "    print(f\"\\nüéØ Model Performance Summary:\")\n",
        "    print(f\"   Model: {perf['MODEL_NAME']} {perf['MODEL_VERSION']}\")\n",
        "    print(f\"   Total Predictions: {perf['TOTAL_PREDICTIONS']:,}\")\n",
        "    print(f\"   Predicted Conversions: {perf['PREDICTED_CONVERSIONS']:,}\")\n",
        "    print(f\"   Actual Conversions: {perf['ACTUAL_CONVERSIONS']:,}\")\n",
        "    print(f\"\\nüìä Performance Metrics:\")\n",
        "    print(f\"   Accuracy: {perf['ACCURACY']:.2%}\")\n",
        "    print(f\"   Precision: {perf['PRECISION']:.2%}\" if perf['PRECISION'] else \"   Precision: N/A\")\n",
        "    print(f\"   Recall: {perf['RECALL']:.2%}\" if perf['RECALL'] else \"   Recall: N/A\")\n",
        "    print(f\"   F1 Score: {perf['F1_SCORE']:.2%}\" if perf['F1_SCORE'] else \"   F1 Score: N/A\")\n",
        "    \n",
        "    # Store performance metrics\n",
        "    session.sql(f\"\"\"\n",
        "        INSERT INTO MODEL_PERFORMANCE_TRACKING \n",
        "        VALUES (\n",
        "            NULL,\n",
        "            CURRENT_TIMESTAMP(),\n",
        "            '{perf['MODEL_NAME']}',\n",
        "            '{perf['MODEL_VERSION']}',\n",
        "            'ACCURACY',\n",
        "            {perf['ACCURACY']},\n",
        "            'PRODUCTION'\n",
        "        )\n",
        "    \"\"\").collect()\n",
        "    \n",
        "    print(\"\\n‚úÖ Performance metrics logged to MODEL_PERFORMANCE_TRACKING\")\n",
        "\n",
        "# Check data quality\n",
        "data_quality_sql = \"\"\"\n",
        "SELECT \n",
        "    COUNT(*) as total_clients,\n",
        "    COUNT(DISTINCT CLIENT_ID) as unique_clients,\n",
        "    AVG(DAYS_SINCE_LAST_ACTIVITY) as avg_days_inactive,\n",
        "    COUNT(CASE WHEN TOTAL_EVENTS_30D IS NULL THEN 1 END) as null_events,\n",
        "    COUNT(CASE WHEN ANNUAL_INCOME IS NULL THEN 1 END) as null_income,\n",
        "    MIN(DAYS_SINCE_LAST_ACTIVITY) as most_active_days_ago,\n",
        "    MAX(DAYS_SINCE_LAST_ACTIVITY) as least_active_days_ago\n",
        "FROM FEATURE_STORE\n",
        "\"\"\"\n",
        "\n",
        "quality_df = session.sql(data_quality_sql).collect()\n",
        "if quality_df:\n",
        "    q = quality_df[0]\n",
        "    print(f\"\\nüìã Data Quality Check:\")\n",
        "    print(f\"   Total Clients: {q['TOTAL_CLIENTS']:,}\")\n",
        "    print(f\"   Unique Clients: {q['UNIQUE_CLIENTS']:,}\")\n",
        "    print(f\"   Avg Days Inactive: {q['AVG_DAYS_INACTIVE']:.1f}\")\n",
        "    print(f\"   Most Active: {q['MOST_ACTIVE_DAYS_AGO']} days ago\")\n",
        "    print(f\"   Least Active: {q['LEAST_ACTIVE_DAYS_AGO']} days ago\")\n",
        "    print(f\"   Null Events: {q['NULL_EVENTS']:,}\")\n",
        "    print(f\"   Null Income: {q['NULL_INCOME']:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Drift Detection and Monitoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect feature drift and prediction drift\n",
        "print(\"üîç Analyzing drift in features and predictions...\")\n",
        "\n",
        "# Feature drift detection\n",
        "feature_drift_sql = \"\"\"\n",
        "WITH feature_baselines AS (\n",
        "    -- Calculate baseline statistics (from random 25% sample for baseline)\n",
        "    SELECT \n",
        "        'ENGAGEMENT_SCORE_30D' as feature_name,\n",
        "        AVG(ENGAGEMENT_SCORE_30D) as baseline_mean,\n",
        "        STDDEV(ENGAGEMENT_SCORE_30D) as baseline_std\n",
        "    FROM FEATURE_STORE \n",
        "    TABLESAMPLE (25)\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'TOTAL_EVENTS_30D',\n",
        "        AVG(TOTAL_EVENTS_30D),\n",
        "        STDDEV(TOTAL_EVENTS_30D)\n",
        "    FROM FEATURE_STORE \n",
        "    TABLESAMPLE (25)\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'DAYS_SINCE_LAST_ACTIVITY',\n",
        "        AVG(DAYS_SINCE_LAST_ACTIVITY),\n",
        "        STDDEV(DAYS_SINCE_LAST_ACTIVITY)\n",
        "    FROM FEATURE_STORE \n",
        "    TABLESAMPLE (25)\n",
        "),\n",
        "current_stats AS (\n",
        "    -- Calculate current statistics (recently active clients only)\n",
        "    SELECT \n",
        "        'ENGAGEMENT_SCORE_30D' as feature_name,\n",
        "        AVG(ENGAGEMENT_SCORE_30D) as current_mean,\n",
        "        STDDEV(ENGAGEMENT_SCORE_30D) as current_std\n",
        "    FROM FEATURE_STORE \n",
        "    WHERE DAYS_SINCE_LAST_ACTIVITY <= 30\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'TOTAL_EVENTS_30D',\n",
        "        AVG(TOTAL_EVENTS_30D),\n",
        "        STDDEV(TOTAL_EVENTS_30D)\n",
        "    FROM FEATURE_STORE \n",
        "    WHERE DAYS_SINCE_LAST_ACTIVITY <= 30\n",
        "    UNION ALL\n",
        "    SELECT \n",
        "        'DAYS_SINCE_LAST_ACTIVITY',\n",
        "        AVG(DAYS_SINCE_LAST_ACTIVITY),\n",
        "        STDDEV(DAYS_SINCE_LAST_ACTIVITY)\n",
        "    FROM FEATURE_STORE \n",
        "    WHERE DAYS_SINCE_LAST_ACTIVITY <= 30\n",
        ")\n",
        "SELECT \n",
        "    b.feature_name,\n",
        "    b.baseline_mean,\n",
        "    c.current_mean,\n",
        "    ABS(c.current_mean - b.baseline_mean) / NULLIF(b.baseline_std, 0) as drift_score,\n",
        "    CASE \n",
        "        WHEN ABS(c.current_mean - b.baseline_mean) / NULLIF(b.baseline_std, 0) > 2 THEN 'High'\n",
        "        WHEN ABS(c.current_mean - b.baseline_mean) / NULLIF(b.baseline_std, 0) > 1 THEN 'Medium'\n",
        "        ELSE 'Low'\n",
        "    END as drift_severity,\n",
        "    CASE \n",
        "        WHEN ABS(c.current_mean - b.baseline_mean) / NULLIF(b.baseline_std, 0) > 2 THEN TRUE\n",
        "        ELSE FALSE\n",
        "    END as alert_triggered\n",
        "FROM feature_baselines b\n",
        "JOIN current_stats c ON b.feature_name = c.feature_name\n",
        "\"\"\"\n",
        "\n",
        "drift_df = session.sql(feature_drift_sql).collect()\n",
        "\n",
        "print(\"\\nüìä Feature Drift Analysis:\")\n",
        "print(\"Feature Name                | Baseline | Current | Drift Score | Severity\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for row in drift_df:\n",
        "    print(f\"{row['FEATURE_NAME']:<26} | {row['BASELINE_MEAN']:>8.2f} | {row['CURRENT_MEAN']:>7.2f} | {row['DRIFT_SCORE']:>11.2f} | {row['DRIFT_SEVERITY']}\")\n",
        "    \n",
        "    # Log drift to monitoring table\n",
        "    if row['ALERT_TRIGGERED']:\n",
        "        session.sql(f\"\"\"\n",
        "            INSERT INTO DATA_DRIFT_MONITORING VALUES (\n",
        "                NULL,\n",
        "                CURRENT_TIMESTAMP(),\n",
        "                '{row['FEATURE_NAME']}',\n",
        "                {row['BASELINE_MEAN']},\n",
        "                {row['CURRENT_MEAN']},\n",
        "                {row['DRIFT_SCORE']},\n",
        "                {row['ALERT_TRIGGERED']}\n",
        "            )\n",
        "        \"\"\").collect()\n",
        "\n",
        "# Prediction drift detection\n",
        "prediction_drift_sql = \"\"\"\n",
        "WITH prediction_windows AS (\n",
        "    SELECT \n",
        "        DATE_TRUNC('day', BATCH_TIMESTAMP) as prediction_date,\n",
        "        AVG(CONVERSION_PROBABILITY) as avg_prediction,\n",
        "        COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) / COUNT(*) as positive_rate,\n",
        "        COUNT(*) as daily_volume\n",
        "    FROM CLIENT_SEGMENTS_BATCH\n",
        "    GROUP BY DATE_TRUNC('day', BATCH_TIMESTAMP)\n",
        "    ORDER BY prediction_date DESC\n",
        "    LIMIT 7\n",
        ")\n",
        "SELECT \n",
        "    prediction_date,\n",
        "    avg_prediction,\n",
        "    positive_rate,\n",
        "    daily_volume,\n",
        "    LAG(positive_rate) OVER (ORDER BY prediction_date) as prev_positive_rate,\n",
        "    ABS(positive_rate - LAG(positive_rate) OVER (ORDER BY prediction_date)) as daily_change\n",
        "FROM prediction_windows\n",
        "ORDER BY prediction_date DESC\n",
        "\"\"\"\n",
        "\n",
        "pred_drift_df = session.sql(prediction_drift_sql).collect()\n",
        "\n",
        "print(\"\\nüìà Prediction Drift Analysis (Last 7 Days):\")\n",
        "print(\"Date       | Positive Rate | Daily Change | Volume\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for row in pred_drift_df:\n",
        "    if row['DAILY_CHANGE'] is not None:\n",
        "        print(f\"{row['PREDICTION_DATE'].strftime('%Y-%m-%d')} | {row['POSITIVE_RATE']:>13.2%} | {row['DAILY_CHANGE']:>12.2%} | {row['DAILY_VOLUME']:>6,}\")\n",
        "\n",
        "print(\"\\n‚úÖ Drift analysis complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Business Impact Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate business impact of ML models\n",
        "print(\"üí∞ Analyzing Business Impact of ML Models...\")\n",
        "\n",
        "# Calculate conversion impact\n",
        "conversion_impact_sql = \"\"\"\n",
        "WITH model_results AS (\n",
        "    SELECT \n",
        "        cs.CLIENT_ID,\n",
        "        cs.RECOMMENDED_ACTION,\n",
        "        cs.SEGMENT,\n",
        "        cs.CONVERSION_PROBABILITY,\n",
        "        f.ANNUAL_INCOME,\n",
        "        f.TOTAL_ASSETS_UNDER_MANAGEMENT,\n",
        "        -- Assume conversion value is 2% of assets + advisory fee\n",
        "        CASE \n",
        "            WHEN cs.CONVERSION_PROBABILITY = 1 THEN \n",
        "                f.TOTAL_ASSETS_UNDER_MANAGEMENT * 0.02 + 1500\n",
        "            ELSE 0 \n",
        "        END as potential_revenue\n",
        "    FROM CLIENT_SEGMENTS_BATCH cs\n",
        "    JOIN FEATURE_STORE f ON cs.CLIENT_ID = f.CLIENT_ID\n",
        "    WHERE cs.BATCH_TIMESTAMP >= DATEADD(day, -7, CURRENT_DATE())\n",
        ")\n",
        "SELECT \n",
        "    COUNT(DISTINCT CLIENT_ID) as clients_targeted,\n",
        "    COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) as predicted_conversions,\n",
        "    SUM(potential_revenue) as total_potential_revenue,\n",
        "    AVG(potential_revenue) as avg_revenue_per_conversion,\n",
        "    SUM(CASE WHEN SEGMENT = 'High Value' THEN potential_revenue ELSE 0 END) as high_value_revenue,\n",
        "    COUNT(CASE WHEN RECOMMENDED_ACTION = 'Wealth_Advisory_Consultation' THEN 1 END) as wealth_advisory_leads\n",
        "FROM model_results\n",
        "\"\"\"\n",
        "\n",
        "conversion_impact_df = session.sql(conversion_impact_sql).collect()\n",
        "\n",
        "if conversion_impact_df:\n",
        "    impact = conversion_impact_df[0]\n",
        "    print(f\"\\nüìä Conversion Model Impact (Last 7 Days):\")\n",
        "    print(f\"   Clients Targeted: {impact['CLIENTS_TARGETED']:,}\")\n",
        "    print(f\"   Predicted Conversions: {impact['PREDICTED_CONVERSIONS']:,}\")\n",
        "    print(f\"   Total Potential Revenue: ${impact['TOTAL_POTENTIAL_REVENUE']:,.2f}\")\n",
        "    print(f\"   Avg Revenue per Conversion: ${impact['AVG_REVENUE_PER_CONVERSION']:,.2f}\")\n",
        "    print(f\"   High Value Segment Revenue: ${impact['HIGH_VALUE_REVENUE']:,.2f}\")\n",
        "    print(f\"   Wealth Advisory Leads: {impact['WEALTH_ADVISORY_LEADS']:,}\")\n",
        "\n",
        "# Calculate churn prevention impact\n",
        "churn_impact_sql = \"\"\"\n",
        "WITH churn_prevention AS (\n",
        "    SELECT \n",
        "        c.CLIENT_ID,\n",
        "        c.CHURN_RISK_SCORE,\n",
        "        c.VALUE_TIER,\n",
        "        c.RECOMMENDED_ACTION,\n",
        "        f.TOTAL_ASSETS_UNDER_MANAGEMENT,\n",
        "        f.ANNUAL_INCOME,\n",
        "        -- Annual revenue from client (1% management fee)\n",
        "        f.TOTAL_ASSETS_UNDER_MANAGEMENT * 0.01 as annual_revenue,\n",
        "        -- Cost of retention action\n",
        "        CASE c.RECOMMENDED_ACTION\n",
        "            WHEN 'Priority Retention Call' THEN 500\n",
        "            WHEN 'Personal Advisory Meeting' THEN 300\n",
        "            WHEN 'Special Offer' THEN 200\n",
        "            ELSE 100\n",
        "        END as retention_cost\n",
        "    FROM CLIENT_CHURN_SEGMENTS c\n",
        "    JOIN FEATURE_STORE f ON c.CLIENT_ID = f.CLIENT_ID\n",
        "    WHERE c.CHURN_RISK_SCORE > 0.6\n",
        ")\n",
        "SELECT \n",
        "    COUNT(*) as at_risk_clients,\n",
        "    SUM(annual_revenue) as revenue_at_risk,\n",
        "    AVG(annual_revenue) as avg_revenue_per_client,\n",
        "    SUM(retention_cost) as total_retention_cost,\n",
        "    SUM(annual_revenue) - SUM(retention_cost) as net_revenue_saved,\n",
        "    COUNT(CASE WHEN VALUE_TIER = 'High' THEN 1 END) as high_value_at_risk\n",
        "FROM churn_prevention\n",
        "\"\"\"\n",
        "\n",
        "churn_impact_df = session.sql(churn_impact_sql).collect()\n",
        "\n",
        "if churn_impact_df:\n",
        "    churn = churn_impact_df[0]\n",
        "    print(f\"\\nüõ°Ô∏è Churn Prevention Impact:\")\n",
        "    print(f\"   At-Risk Clients: {churn['AT_RISK_CLIENTS']:,}\")\n",
        "    print(f\"   Revenue at Risk: ${churn['REVENUE_AT_RISK']:,.2f}\")\n",
        "    print(f\"   Avg Revenue per Client: ${churn['AVG_REVENUE_PER_CLIENT']:,.2f}\")\n",
        "    print(f\"   Total Retention Cost: ${churn['TOTAL_RETENTION_COST']:,.2f}\")\n",
        "    print(f\"   Net Revenue Saved: ${churn['NET_REVENUE_SAVED']:,.2f}\")\n",
        "    print(f\"   High Value Clients at Risk: {churn['HIGH_VALUE_AT_RISK']:,}\")\n",
        "\n",
        "# Store business impact metrics\n",
        "try:\n",
        "    session.sql(f\"\"\"\n",
        "        INSERT INTO ML_BUSINESS_IMPACT VALUES (\n",
        "            NULL,\n",
        "            CURRENT_DATE(),\n",
        "            'CONVERSION_PREDICTOR',\n",
        "            'V1',\n",
        "            {impact['PREDICTED_CONVERSIONS']},\n",
        "            {impact['PREDICTED_CONVERSIONS'] / impact['CLIENTS_TARGETED']},\n",
        "            {impact['TOTAL_POTENTIAL_REVENUE']},\n",
        "            {churn['AT_RISK_CLIENTS'] if churn_impact_df else 0},\n",
        "            {1 - (churn['AT_RISK_CLIENTS'] / impact['CLIENTS_TARGETED']) if churn_impact_df else 0},\n",
        "            {churn['NET_REVENUE_SAVED'] if churn_impact_df else 0},\n",
        "            {impact['TOTAL_POTENTIAL_REVENUE'] + (churn['NET_REVENUE_SAVED'] if churn_impact_df else 0)},\n",
        "            {((impact['TOTAL_POTENTIAL_REVENUE'] + (churn['NET_REVENUE_SAVED'] if churn_impact_df else 0)) / \n",
        "              (churn['TOTAL_RETENTION_COST'] if churn_impact_df else 1) - 1) * 100}\n",
        "        )\n",
        "    \"\"\").collect()\n",
        "    print(\"\\n‚úÖ Business impact metrics logged\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è Could not log business impact: {str(e)}\")\n",
        "\n",
        "print(\"\\nüéØ Total Business Value Generated: ${:,.2f}\".format(\n",
        "    impact['TOTAL_POTENTIAL_REVENUE'] + (churn['NET_REVENUE_SAVED'] if churn_impact_df else 0)\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Comprehensive Observability Dashboard & Alerts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive observability dashboard views\n",
        "print(\"üìä Creating ML Observability Dashboard...\")\n",
        "\n",
        "# Create unified dashboard view\n",
        "dashboard_sql = \"\"\"\n",
        "CREATE OR REPLACE VIEW ML_OBSERVABILITY_DASHBOARD AS\n",
        "WITH model_metrics AS (\n",
        "    SELECT \n",
        "        MODEL_NAME,\n",
        "        MODEL_VERSION,\n",
        "        MAX(EVALUATION_TIMESTAMP) as last_evaluated,\n",
        "        AVG(METRIC_VALUE) as avg_accuracy,\n",
        "        MIN(METRIC_VALUE) as min_accuracy,\n",
        "        MAX(METRIC_VALUE) as max_accuracy\n",
        "    FROM MODEL_PERFORMANCE_TRACKING\n",
        "    WHERE METRIC_NAME = 'ACCURACY'\n",
        "    GROUP BY MODEL_NAME, MODEL_VERSION\n",
        "),\n",
        "drift_summary AS (\n",
        "    SELECT \n",
        "        COUNT(DISTINCT FEATURE_NAME) as drifted_features,\n",
        "        MAX(DRIFT_SCORE) as max_drift_score,\n",
        "        MAX(MONITORING_TIMESTAMP) as last_drift_check\n",
        "    FROM DATA_DRIFT_MONITORING\n",
        "    WHERE ALERT_TRIGGERED = TRUE\n",
        "),\n",
        "prediction_volume AS (\n",
        "    SELECT \n",
        "        COUNT(*) as daily_predictions,\n",
        "        COUNT(CASE WHEN CONVERSION_PROBABILITY = 1 THEN 1 END) as positive_predictions,\n",
        "        COUNT(DISTINCT CLIENT_ID) as unique_clients\n",
        "    FROM CLIENT_SEGMENTS_BATCH\n",
        "    WHERE BATCH_TIMESTAMP >= CURRENT_DATE()\n",
        "),\n",
        "business_metrics AS (\n",
        "    SELECT \n",
        "        SUM(total_business_value) as total_value,\n",
        "        AVG(roi_percentage) as avg_roi,\n",
        "        SUM(total_conversions) as total_conversions,\n",
        "        SUM(churns_prevented) as total_churns_prevented\n",
        "    FROM ML_BUSINESS_IMPACT\n",
        "    WHERE evaluation_date >= DATEADD(day, -30, CURRENT_DATE())\n",
        ")\n",
        "SELECT \n",
        "    -- Model Performance\n",
        "    m.MODEL_NAME,\n",
        "    m.MODEL_VERSION,\n",
        "    m.avg_accuracy,\n",
        "    m.last_evaluated,\n",
        "    \n",
        "    -- Data Quality\n",
        "    d.drifted_features,\n",
        "    d.max_drift_score,\n",
        "    \n",
        "    -- Prediction Volume\n",
        "    p.daily_predictions,\n",
        "    p.positive_predictions,\n",
        "    p.unique_clients,\n",
        "    \n",
        "    -- Business Impact\n",
        "    b.total_value,\n",
        "    b.avg_roi,\n",
        "    b.total_conversions,\n",
        "    b.total_churns_prevented,\n",
        "    \n",
        "    -- Health Status\n",
        "    CASE \n",
        "        WHEN m.avg_accuracy < 0.6 THEN 'Critical'\n",
        "        WHEN d.drifted_features > 3 THEN 'Warning'\n",
        "        WHEN d.max_drift_score > 2 THEN 'Warning'\n",
        "        ELSE 'Healthy'\n",
        "    END as model_health_status,\n",
        "    \n",
        "    CURRENT_TIMESTAMP() as dashboard_updated\n",
        "FROM model_metrics m\n",
        "CROSS JOIN drift_summary d\n",
        "CROSS JOIN prediction_volume p\n",
        "CROSS JOIN business_metrics b\n",
        "\"\"\"\n",
        "\n",
        "session.sql(dashboard_sql).collect()\n",
        "print(\"‚úÖ Created ML_OBSERVABILITY_DASHBOARD view\")\n",
        "\n",
        "# Check dashboard\n",
        "dashboard_df = session.sql(\"SELECT * FROM ML_OBSERVABILITY_DASHBOARD\").collect()\n",
        "\n",
        "if dashboard_df:\n",
        "    dash = dashboard_df[0]\n",
        "    print(f\"\\nüéØ ML System Health Dashboard\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(f\"\\nüìä Model Performance:\")\n",
        "    print(f\"   Model: {dash['MODEL_NAME']} {dash['MODEL_VERSION']}\")\n",
        "    print(f\"   Average Accuracy: {dash['AVG_ACCURACY']:.2%}\")\n",
        "    print(f\"   Last Evaluated: {dash['LAST_EVALUATED']}\")\n",
        "    \n",
        "    print(f\"\\nüîç Data Quality:\")\n",
        "    print(f\"   Drifted Features: {dash['DRIFTED_FEATURES']}\")\n",
        "    print(f\"   Max Drift Score: {dash['MAX_DRIFT_SCORE']:.2f}\")\n",
        "    \n",
        "    print(f\"\\nüìà Today's Activity:\")\n",
        "    print(f\"   Predictions: {dash['DAILY_PREDICTIONS']:,}\")\n",
        "    print(f\"   Positive Rate: {dash['POSITIVE_PREDICTIONS'] / dash['DAILY_PREDICTIONS']:.2%}\")\n",
        "    print(f\"   Unique Clients: {dash['UNIQUE_CLIENTS']:,}\")\n",
        "    \n",
        "    print(f\"\\nüí∞ Business Impact (30 Days):\")\n",
        "    print(f\"   Total Value: ${dash['TOTAL_VALUE']:,.2f}\")\n",
        "    print(f\"   Average ROI: {dash['AVG_ROI']:.1f}%\")\n",
        "    print(f\"   Conversions: {dash['TOTAL_CONVERSIONS']:,}\")\n",
        "    print(f\"   Churns Prevented: {dash['TOTAL_CHURNS_PREVENTED']:,}\")\n",
        "    \n",
        "    print(f\"\\nüö¶ System Status: {dash['MODEL_HEALTH_STATUS']}\")\n",
        "\n",
        "# Set up automated alerts\n",
        "alert_procedure_sql = \"\"\"\n",
        "CREATE OR REPLACE PROCEDURE CHECK_ML_ALERTS()\n",
        "RETURNS VARCHAR\n",
        "LANGUAGE SQL\n",
        "AS\n",
        "$$\n",
        "DECLARE\n",
        "    alert_message VARCHAR;\n",
        "    accuracy_threshold FLOAT := 0.65;\n",
        "    drift_threshold FLOAT := 2.0;\n",
        "BEGIN\n",
        "    -- Check model performance\n",
        "    SELECT INTO alert_message\n",
        "        CASE \n",
        "            WHEN AVG(METRIC_VALUE) < :accuracy_threshold THEN \n",
        "                'ALERT: Model accuracy below threshold - ' || AVG(METRIC_VALUE)\n",
        "            ELSE NULL\n",
        "        END\n",
        "    FROM MODEL_PERFORMANCE_TRACKING\n",
        "    WHERE METRIC_NAME = 'ACCURACY'\n",
        "    AND EVALUATION_TIMESTAMP >= DATEADD(hour, -24, CURRENT_TIMESTAMP());\n",
        "    \n",
        "    IF (alert_message IS NOT NULL) THEN\n",
        "        RETURN alert_message;\n",
        "    END IF;\n",
        "    \n",
        "    -- Check drift\n",
        "    SELECT INTO alert_message\n",
        "        CASE \n",
        "            WHEN MAX(DRIFT_SCORE) > :drift_threshold THEN \n",
        "                'ALERT: High feature drift detected - ' || MAX(DRIFT_SCORE)\n",
        "            ELSE NULL\n",
        "        END\n",
        "    FROM DATA_DRIFT_MONITORING\n",
        "    WHERE MONITORING_TIMESTAMP >= DATEADD(hour, -24, CURRENT_TIMESTAMP());\n",
        "    \n",
        "    IF (alert_message IS NOT NULL) THEN\n",
        "        RETURN alert_message;\n",
        "    END IF;\n",
        "    \n",
        "    RETURN 'All systems normal';\n",
        "END;\n",
        "$$\n",
        "\"\"\"\n",
        "\n",
        "session.sql(alert_procedure_sql).collect()\n",
        "print(\"\\n‚úÖ Created alert monitoring procedure\")\n",
        "\n",
        "# Check for current alerts\n",
        "alert_result = session.sql(\"CALL CHECK_ML_ALERTS()\").collect()\n",
        "print(f\"\\nüö® Alert Status: {alert_result[0][0]}\")\n",
        "\n",
        "print(\"\\nüéâ ML Observability Suite Complete!\")\n",
        "print(\"\\nüìù Next Steps:\")\n",
        "print(\"   1. Schedule MONITOR_PREDICTIONS task to run every 6 hours\")\n",
        "print(\"   2. Set up email alerts for critical model health\")\n",
        "print(\"   3. Create Snowsight dashboards using ML_OBSERVABILITY_DASHBOARD\")\n",
        "print(\"   4. Review business impact weekly\")\n",
        "print(\"   5. Retrain models when accuracy drops below 65%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
