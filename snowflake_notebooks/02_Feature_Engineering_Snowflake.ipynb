{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering for Financial ML Pipeline\n",
        "\n",
        "This notebook creates comprehensive features for predicting:\n",
        "- Next best action for client engagement\n",
        "- Client conversion likelihood\n",
        "- Client churn risk\n",
        "\n",
        "## Features Created:\n",
        "1. **Engagement Metrics** - Web visits, email interactions, campaign responses\n",
        "2. **Financial Indicators** - Income, assets, retirement readiness\n",
        "3. **Behavioral Patterns** - Preferences, lifecycle stage, engagement trends\n",
        "4. **Target Variables** - Conversion, churn, next best action\n",
        "\n",
        "## Workflow:\n",
        "1. Run Cells 1-10 to create all features\n",
        "2. Run Cell 11 to register in Feature Store (if needed for UI visibility)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import snowflake.snowpark as snowpark\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import *\n",
        "from snowflake.snowpark.window import Window\n",
        "from snowflake.ml.feature_store import FeatureStore, Entity, FeatureView\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get active session\n",
        "session = snowpark.session._get_active_session()\n",
        "\n",
        "print(f\"üîß Snowflake Feature Engineering Pipeline\")\n",
        "print(f\"Database: {session.get_current_database()}\")\n",
        "print(f\"Schema: {session.get_current_schema()}\")\n",
        "print(f\"Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Verify data availability and ensure correct schema\n",
        "print(f\"\\nüîç Checking data availability...\")\n",
        "\n",
        "# Check current schema and find data tables\n",
        "current_schema = session.get_current_schema()\n",
        "print(f\"üìç Current schema: {current_schema}\")\n",
        "\n",
        "try:\n",
        "    client_count = session.sql(\"SELECT COUNT(*) as count FROM clients\").collect()[0]['COUNT']\n",
        "    event_count = session.sql(\"SELECT COUNT(*) as count FROM marketing_events\").collect()[0]['COUNT']\n",
        "    \n",
        "    print(f\"\\n‚úÖ Data Available in {current_schema}:\")\n",
        "    print(f\"üìä Clients: {client_count:,}\")\n",
        "    print(f\"üìä Marketing Events: {event_count:,}\")\n",
        "    \n",
        "    # Check marketing_events table structure\n",
        "    print(\"\\nüîç Marketing Events Table Structure:\")\n",
        "    session.sql(\"DESCRIBE TABLE marketing_events\").show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Data tables not found in {current_schema}: {e}\")\n",
        "    print(\"üîÑ Attempting to find data in ML_PIPELINE schema...\")\n",
        "    \n",
        "    try:\n",
        "        # Try ML_PIPELINE schema\n",
        "        session.sql(\"USE SCHEMA ML_PIPELINE\").collect()\n",
        "        client_count = session.sql(\"SELECT COUNT(*) as count FROM clients\").collect()[0]['COUNT']\n",
        "        event_count = session.sql(\"SELECT COUNT(*) as count FROM marketing_events\").collect()[0]['COUNT']\n",
        "        \n",
        "        print(f\"\\n‚úÖ Data Found in ML_PIPELINE schema:\")\n",
        "        print(f\"üìä Clients: {client_count:,}\")\n",
        "        print(f\"üìä Marketing Events: {event_count:,}\")\n",
        "        \n",
        "        print(\"\\nüîç Marketing Events Table Structure:\")\n",
        "        session.sql(\"DESCRIBE TABLE marketing_events\").show()\n",
        "        \n",
        "    except Exception as e2:\n",
        "        print(f\"‚ùå Data tables not found in any schema: {e2}\")\n",
        "        print(\"üìã Please run the data generation notebook (01_Data_Generation_Snowflake.ipynb) first\")\n",
        "        print(\"   This will create the required CLIENTS and MARKETING_EVENTS tables\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Engagement Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive engagement features using Snowflake SQL\n",
        "print(\"üéØ Creating engagement features across multiple time windows...\")\n",
        "\n",
        "engagement_features_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE engagement_features AS\n",
        "WITH time_windows AS (\n",
        "  SELECT \n",
        "    client_id,\n",
        "    \n",
        "    -- 7-day engagement metrics\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -7, CURRENT_TIMESTAMP()) THEN 1 END) as total_events_7d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -7, CURRENT_TIMESTAMP()) AND event_type = 'web_visit' THEN 1 END) as web_visits_7d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -7, CURRENT_TIMESTAMP()) AND event_type = 'email_open' THEN 1 END) as email_opens_7d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -7, CURRENT_TIMESTAMP()) AND event_type = 'email_click' THEN 1 END) as email_clicks_7d,\n",
        "    \n",
        "    -- 30-day engagement metrics\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) THEN 1 END) as total_events_30d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND event_type = 'web_visit' THEN 1 END) as web_visits_30d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND event_type = 'email_open' THEN 1 END) as email_opens_30d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND event_type = 'email_click' THEN 1 END) as email_clicks_30d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND event_type = 'advisor_meeting' THEN 1 END) as personal_interactions_30d,\n",
        "    \n",
        "    -- 90-day engagement metrics\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -90, CURRENT_TIMESTAMP()) THEN 1 END) as total_events_90d,\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -90, CURRENT_TIMESTAMP()) AND event_type = 'web_visit' THEN 1 END) as web_visits_90d,\n",
        "    \n",
        "    -- Session quality metrics\n",
        "    AVG(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND time_on_page IS NOT NULL \n",
        "             THEN time_on_page END) as avg_session_duration_30d,\n",
        "    MAX(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND time_on_page IS NOT NULL \n",
        "            THEN time_on_page END) as max_session_duration_30d,\n",
        "    \n",
        "    -- Engagement consistency\n",
        "    COUNT(DISTINCT CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) \n",
        "                        THEN DATE(event_timestamp) END) as active_days_30d,\n",
        "    \n",
        "    -- Touchpoint value (if column exists, otherwise use default)\n",
        "    SUM(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) \n",
        "             THEN COALESCE(touchpoint_value, 0.5) END) as total_touchpoint_value_30d,\n",
        "    AVG(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) \n",
        "             THEN COALESCE(touchpoint_value, 0.5) END) as avg_touchpoint_value_30d,\n",
        "    \n",
        "    -- Conversion indicators (if column exists)\n",
        "    COUNT(CASE WHEN event_timestamp >= DATEADD(day, -30, CURRENT_TIMESTAMP()) AND COALESCE(conversion_flag, FALSE) = TRUE \n",
        "               THEN 1 END) as conversions_30d,\n",
        "    \n",
        "    -- Activity recency\n",
        "    MAX(event_timestamp) as last_activity_timestamp,\n",
        "    DATEDIFF(day, MAX(event_timestamp), CURRENT_TIMESTAMP()) as days_since_last_activity\n",
        "    \n",
        "  FROM marketing_events \n",
        "  GROUP BY client_id\n",
        "),\n",
        "\n",
        "calculated_metrics AS (\n",
        "  SELECT \n",
        "    *,\n",
        "    -- Engagement frequency calculations\n",
        "    CASE WHEN active_days_30d > 0 THEN total_events_30d::DECIMAL / active_days_30d ELSE 0 END as engagement_frequency_30d,\n",
        "    \n",
        "    -- Email engagement rates\n",
        "    CASE WHEN email_opens_30d > 0 THEN email_clicks_30d::DECIMAL / email_opens_30d ELSE 0 END as email_click_rate_30d,\n",
        "    \n",
        "    -- Trend indicators (comparing recent vs older activity)\n",
        "    CASE WHEN total_events_90d > 0 THEN total_events_30d::DECIMAL / (total_events_90d / 3) ELSE 0 END as engagement_trend_30d,\n",
        "    \n",
        "    -- Engagement score (composite metric)\n",
        "    LEAST(1.0, \n",
        "      (total_events_30d * 0.3 + \n",
        "       web_visits_30d * 0.2 + \n",
        "       email_opens_30d * 0.2 + \n",
        "       personal_interactions_30d * 0.3) / 100\n",
        "    ) as engagement_score_30d\n",
        "    \n",
        "  FROM time_windows\n",
        ")\n",
        "\n",
        "SELECT \n",
        "  client_id,\n",
        "  CURRENT_TIMESTAMP() as feature_timestamp,\n",
        "  \n",
        "  -- Raw engagement counts\n",
        "  total_events_7d, web_visits_7d, email_opens_7d, email_clicks_7d,\n",
        "  total_events_30d, web_visits_30d, email_opens_30d, email_clicks_30d, personal_interactions_30d,\n",
        "  total_events_90d, web_visits_90d,\n",
        "  \n",
        "  -- Quality metrics\n",
        "  ROUND(avg_session_duration_30d, 2) as avg_session_duration_30d,\n",
        "  max_session_duration_30d,\n",
        "  active_days_30d,\n",
        "  \n",
        "  -- Value metrics\n",
        "  ROUND(total_touchpoint_value_30d, 4) as total_touchpoint_value_30d,\n",
        "  ROUND(avg_touchpoint_value_30d, 4) as avg_touchpoint_value_30d,\n",
        "  conversions_30d,\n",
        "  \n",
        "  -- Recency\n",
        "  last_activity_timestamp,\n",
        "  days_since_last_activity,\n",
        "  \n",
        "  -- Calculated metrics\n",
        "  ROUND(engagement_frequency_30d, 4) as engagement_frequency_30d,\n",
        "  ROUND(email_click_rate_30d, 4) as email_click_rate_30d,\n",
        "  ROUND(engagement_trend_30d, 4) as engagement_trend_30d,\n",
        "  ROUND(engagement_score_30d, 4) as engagement_score_30d\n",
        "  \n",
        "FROM calculated_metrics\n",
        "\"\"\"\n",
        "\n",
        "# Execute feature creation\n",
        "session.sql(engagement_features_sql).collect()\n",
        "\n",
        "# Verify results\n",
        "engagement_count = session.sql(\"SELECT COUNT(*) as count FROM engagement_features\").collect()[0]['COUNT']\n",
        "print(f\"‚úÖ Created engagement features for {engagement_count:,} clients\")\n",
        "\n",
        "# Show sample features\n",
        "print(\"\\nüìä Sample engagement features:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT client_id, total_events_30d, web_visits_30d, email_opens_30d, \n",
        "           engagement_frequency_30d, engagement_score_30d, days_since_last_activity\n",
        "    FROM engagement_features \n",
        "    WHERE total_events_30d > 0\n",
        "    ORDER BY engagement_score_30d DESC \n",
        "    LIMIT 10\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Financial & Behavioral Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create financial profile and behavioral features\n",
        "print(\"üí∞ Creating financial and behavioral features...\")\n",
        "\n",
        "financial_behavioral_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE financial_behavioral_features AS\n",
        "WITH client_behaviors AS (\n",
        "  SELECT \n",
        "    me.client_id,\n",
        "    \n",
        "    -- Channel preferences\n",
        "    COUNT(CASE WHEN me.channel = 'Website' THEN 1 END) as web_preference_count,\n",
        "    COUNT(CASE WHEN me.channel = 'Email' THEN 1 END) as email_preference_count,\n",
        "    COUNT(CASE WHEN me.channel = 'Phone' THEN 1 END) as phone_preference_count,\n",
        "    COUNT(CASE WHEN me.channel = 'In-Person' THEN 1 END) as inperson_preference_count,\n",
        "    \n",
        "    -- Device preferences\n",
        "    COUNT(CASE WHEN me.device_type = 'Desktop' THEN 1 END) as desktop_usage,\n",
        "    COUNT(CASE WHEN me.device_type = 'Mobile' THEN 1 END) as mobile_usage,\n",
        "    COUNT(CASE WHEN me.device_type = 'Tablet' THEN 1 END) as tablet_usage,\n",
        "    \n",
        "    -- Behavioral patterns\n",
        "    COUNT(*) as total_lifetime_events,\n",
        "    COUNT(CASE WHEN me.event_type = 'document_download' THEN 1 END) as education_engagement,\n",
        "    COUNT(CASE WHEN me.event_type = 'advisor_meeting' THEN 1 END) as advisor_meetings_total,\n",
        "    AVG(me.touchpoint_value) as avg_touchpoint_value,\n",
        "    \n",
        "    -- Engagement span\n",
        "    DATEDIFF(day, MIN(me.event_timestamp), MAX(me.event_timestamp)) as engagement_span_days\n",
        "    \n",
        "  FROM marketing_events me\n",
        "  GROUP BY me.client_id\n",
        "),\n",
        "\n",
        "financial_profile AS (\n",
        "  SELECT \n",
        "    c.client_id,\n",
        "    c.age,\n",
        "    c.annual_income,\n",
        "    c.current_401k_balance,\n",
        "    c.years_to_retirement,\n",
        "    c.total_assets_under_management,\n",
        "    c.client_tenure_months,\n",
        "    c.service_tier,\n",
        "    c.risk_tolerance,\n",
        "    c.investment_experience,\n",
        "    \n",
        "    -- Financial ratios and scores\n",
        "    ROUND(c.annual_income::DECIMAL / GREATEST(c.age, 25), 2) as income_to_age_ratio,\n",
        "    ROUND(c.total_assets_under_management::DECIMAL / GREATEST(c.annual_income, 1), 4) as assets_to_income_ratio,\n",
        "    \n",
        "    -- Retirement readiness (simplified model)\n",
        "    LEAST(1.0, GREATEST(0.0, \n",
        "      c.current_401k_balance::DECIMAL / GREATEST((c.annual_income * 10), 1)\n",
        "    )) as retirement_readiness_score,\n",
        "    \n",
        "    -- Wealth growth potential\n",
        "    LEAST(1.0, \n",
        "      ((65 - c.age) / 40 * 0.3) + \n",
        "      (LN(c.annual_income) / LN(200000) * 0.4) + \n",
        "      (LN(GREATEST(c.total_assets_under_management, 1)) / LN(1000000) * 0.3)\n",
        "    ) as wealth_growth_potential,\n",
        "    \n",
        "    -- Premium client indicator\n",
        "    CASE WHEN c.total_assets_under_management > 100000 THEN 1 ELSE 0 END as premium_client_indicator,\n",
        "    \n",
        "    -- Service tier numeric\n",
        "    CASE c.service_tier \n",
        "      WHEN 'Basic' THEN 1 \n",
        "      WHEN 'Premium' THEN 2 \n",
        "      WHEN 'Elite' THEN 3 \n",
        "      ELSE 0 \n",
        "    END as service_tier_numeric,\n",
        "    \n",
        "    -- Risk tolerance numeric\n",
        "    CASE c.risk_tolerance \n",
        "      WHEN 'Conservative' THEN 1 \n",
        "      WHEN 'Moderate' THEN 2 \n",
        "      WHEN 'Aggressive' THEN 3 \n",
        "      ELSE 0 \n",
        "    END as risk_tolerance_numeric,\n",
        "    \n",
        "    -- Investment experience numeric\n",
        "    CASE c.investment_experience \n",
        "      WHEN 'Beginner' THEN 1 \n",
        "      WHEN 'Intermediate' THEN 2 \n",
        "      WHEN 'Advanced' THEN 3 \n",
        "      ELSE 0 \n",
        "    END as investment_experience_numeric\n",
        "    \n",
        "  FROM clients c\n",
        ")\n",
        "\n",
        "SELECT \n",
        "  fp.client_id,\n",
        "  CURRENT_TIMESTAMP() as feature_timestamp,\n",
        "  \n",
        "  -- Financial features\n",
        "  fp.age, fp.annual_income, fp.current_401k_balance, fp.years_to_retirement,\n",
        "  fp.total_assets_under_management, fp.client_tenure_months,\n",
        "  fp.income_to_age_ratio, fp.assets_to_income_ratio,\n",
        "  ROUND(fp.retirement_readiness_score, 4) as retirement_readiness_score,\n",
        "  ROUND(fp.wealth_growth_potential, 4) as wealth_growth_potential,\n",
        "  fp.premium_client_indicator,\n",
        "  fp.service_tier_numeric, fp.risk_tolerance_numeric, fp.investment_experience_numeric,\n",
        "  \n",
        "  -- Behavioral features\n",
        "  COALESCE(cb.total_lifetime_events, 0) as total_lifetime_events,\n",
        "  COALESCE(cb.engagement_span_days, 0) as engagement_span_days,\n",
        "  COALESCE(cb.education_engagement, 0) as education_engagement,\n",
        "  COALESCE(cb.advisor_meetings_total, 0) as advisor_meetings_total,\n",
        "  \n",
        "  -- Channel preference ratios\n",
        "  ROUND(COALESCE(cb.web_preference_count, 0)::DECIMAL / GREATEST(cb.total_lifetime_events, 1), 4) as web_preference_ratio,\n",
        "  ROUND(COALESCE(cb.email_preference_count, 0)::DECIMAL / GREATEST(cb.total_lifetime_events, 1), 4) as email_preference_ratio,\n",
        "  ROUND(COALESCE(cb.phone_preference_count, 0)::DECIMAL / GREATEST(cb.total_lifetime_events, 1), 4) as phone_preference_ratio,\n",
        "  ROUND(COALESCE(cb.inperson_preference_count, 0)::DECIMAL / GREATEST(cb.total_lifetime_events, 1), 4) as inperson_preference_ratio,\n",
        "  \n",
        "  -- Device adoption\n",
        "  ROUND(COALESCE(cb.mobile_usage, 0)::DECIMAL / GREATEST((cb.mobile_usage + cb.desktop_usage), 1), 4) as mobile_adoption_score,\n",
        "  \n",
        "  -- Overall engagement frequency\n",
        "  ROUND(COALESCE(cb.total_lifetime_events, 0)::DECIMAL / GREATEST(cb.engagement_span_days, 1), 4) as lifetime_engagement_frequency,\n",
        "  \n",
        "  -- Average value\n",
        "  ROUND(COALESCE(cb.avg_touchpoint_value, 0), 4) as avg_touchpoint_value\n",
        "  \n",
        "FROM financial_profile fp\n",
        "LEFT JOIN client_behaviors cb ON fp.client_id = cb.client_id\n",
        "\"\"\"\n",
        "\n",
        "# Execute feature creation\n",
        "session.sql(financial_behavioral_sql).collect()\n",
        "\n",
        "# Verify results\n",
        "fb_count = session.sql(\"SELECT COUNT(*) as count FROM financial_behavioral_features\").collect()[0]['COUNT']\n",
        "print(f\"‚úÖ Created financial & behavioral features for {fb_count:,} clients\")\n",
        "\n",
        "# Show feature distributions\n",
        "print(\"\\nüìà Financial feature distributions:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        ROUND(AVG(retirement_readiness_score), 4) as avg_retirement_readiness,\n",
        "        ROUND(AVG(wealth_growth_potential), 4) as avg_wealth_potential,\n",
        "        ROUND(AVG(mobile_adoption_score), 4) as avg_mobile_adoption,\n",
        "        COUNT(CASE WHEN premium_client_indicator = 1 THEN 1 END) as premium_clients,\n",
        "        ROUND(AVG(lifetime_engagement_frequency), 4) as avg_engagement_freq\n",
        "    FROM financial_behavioral_features\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Target Variables & Lifecycle Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create target variables and lifecycle features\n",
        "print(\"üéØ Creating target variables and lifecycle features...\")\n",
        "\n",
        "# First, check if engagement_features table exists\n",
        "try:\n",
        "    engagement_check = session.sql(\"\"\"\n",
        "        SELECT COUNT(*) as table_exists \n",
        "        FROM INFORMATION_SCHEMA.TABLES \n",
        "        WHERE TABLE_NAME = 'ENGAGEMENT_FEATURES' \n",
        "        AND TABLE_SCHEMA = CURRENT_SCHEMA()\n",
        "    \"\"\").collect()[0]['TABLE_EXISTS']\n",
        "    \n",
        "    if engagement_check == 0:\n",
        "        print(\"‚ùå ERROR: engagement_features table not found!\")\n",
        "        print(\"   üìã Please run Step 1 (Create Engagement Features) first\")\n",
        "        print(\"   üîÑ Run cell 3 to create the engagement_features table\")\n",
        "        raise Exception(\"Missing dependency: engagement_features table must be created first\")\n",
        "    else:\n",
        "        print(\"‚úÖ engagement_features table verified\")\n",
        "        \n",
        "except Exception as e:\n",
        "    if \"Missing dependency\" in str(e):\n",
        "        raise e\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Warning checking engagement_features: {e}\")\n",
        "\n",
        "targets_lifecycle_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE targets_lifecycle_features AS\n",
        "WITH lifecycle_analysis AS (\n",
        "  SELECT \n",
        "    c.client_id,\n",
        "    c.client_tenure_months,\n",
        "    c.age,\n",
        "    c.service_tier,\n",
        "    c.annual_income,\n",
        "    c.total_assets_under_management,\n",
        "    ef.days_since_last_activity,\n",
        "    ef.engagement_score_30d,\n",
        "    \n",
        "    -- Lifecycle stage determination\n",
        "    CASE \n",
        "      WHEN ef.days_since_last_activity IS NULL OR ef.days_since_last_activity > 180 THEN 'Dormant'\n",
        "      WHEN ef.days_since_last_activity > 90 THEN 'At_Risk'\n",
        "      WHEN c.client_tenure_months < 6 THEN 'New'\n",
        "      WHEN c.client_tenure_months < 18 THEN 'Growing'\n",
        "      ELSE 'Active'\n",
        "    END as lifecycle_stage,\n",
        "    \n",
        "    -- Age segments\n",
        "    CASE \n",
        "      WHEN c.age < 35 THEN 'Young'\n",
        "      WHEN c.age < 50 THEN 'Mid-Career'\n",
        "      WHEN c.age < 60 THEN 'Pre-Retirement'\n",
        "      ELSE 'Near-Retirement'\n",
        "    END as age_segment,\n",
        "    \n",
        "    -- Tenure segments\n",
        "    CASE \n",
        "      WHEN c.client_tenure_months < 6 THEN 'New'\n",
        "      WHEN c.client_tenure_months < 18 THEN 'Growing'\n",
        "      WHEN c.client_tenure_months < 36 THEN 'Established'\n",
        "      ELSE 'Mature'\n",
        "    END as tenure_segment\n",
        "    \n",
        "  FROM clients c\n",
        "  LEFT JOIN engagement_features ef ON c.client_id = ef.client_id\n",
        "),\n",
        "\n",
        "target_generation AS (\n",
        "  SELECT \n",
        "    *,\n",
        "    -- Conversion probability based on multiple factors\n",
        "    LEAST(0.95, GREATEST(0.05,\n",
        "      (CASE service_tier WHEN 'Elite' THEN 0.3 WHEN 'Premium' THEN 0.2 ELSE 0.1 END) +\n",
        "      (CASE WHEN annual_income > 75000 THEN 0.2 ELSE 0.1 END) +\n",
        "      (CASE WHEN total_assets_under_management > 50000 THEN 0.2 ELSE 0.1 END) +\n",
        "      (COALESCE(engagement_score_30d, 0) * 0.3) +\n",
        "      (UNIFORM(0, 0.1, RANDOM()))\n",
        "    )) as conversion_probability,\n",
        "    \n",
        "    -- Churn probability (inverse relationship with conversion)\n",
        "    LEAST(0.8, GREATEST(0.05,\n",
        "      0.4 - \n",
        "      (CASE service_tier WHEN 'Elite' THEN 0.2 WHEN 'Premium' THEN 0.15 ELSE 0.05 END) -\n",
        "      (COALESCE(engagement_score_30d, 0) * 0.2) +\n",
        "      (CASE WHEN days_since_last_activity > 60 THEN 0.3 ELSE 0.0 END) +\n",
        "      (UNIFORM(-0.1, 0.1, RANDOM()))\n",
        "    )) as churn_probability\n",
        "    \n",
        "  FROM lifecycle_analysis\n",
        ")\n",
        "\n",
        "SELECT \n",
        "  client_id,\n",
        "  CURRENT_TIMESTAMP() as feature_timestamp,\n",
        "  \n",
        "  -- Lifecycle features\n",
        "  lifecycle_stage,\n",
        "  age_segment,\n",
        "  tenure_segment,\n",
        "  days_since_last_activity,\n",
        "  \n",
        "  -- Target probabilities\n",
        "  ROUND(conversion_probability, 4) as conversion_probability,\n",
        "  ROUND(churn_probability, 4) as churn_probability,\n",
        "  \n",
        "  -- Binary targets (using probabilistic sampling)\n",
        "  CASE WHEN UNIFORM(0, 1, RANDOM()) < conversion_probability THEN 1 ELSE 0 END as conversion_target,\n",
        "  CASE WHEN UNIFORM(0, 1, RANDOM()) < churn_probability THEN 1 ELSE 0 END as churn_target,\n",
        "  \n",
        "  -- Next best action based on client profile\n",
        "  CASE \n",
        "    WHEN service_tier = 'Basic' AND conversion_probability > 0.3 THEN 'Upgrade_Service_Tier'\n",
        "    WHEN total_assets_under_management < 25000 AND conversion_probability > 0.25 THEN 'Schedule_Planning_Session'\n",
        "    WHEN age_segment = 'Near-Retirement' AND conversion_probability > 0.2 THEN 'Retirement_Planning_Review'\n",
        "    WHEN conversion_probability > 0.4 THEN 'Wealth_Advisory_Consultation'\n",
        "    WHEN conversion_probability < 0.1 THEN 'Educational_Content'\n",
        "    ELSE 'Relationship_Building'\n",
        "  END as next_best_action,\n",
        "  \n",
        "  -- Business priority score\n",
        "  ROUND(\n",
        "    (conversion_probability * 0.4) + \n",
        "    ((1 - churn_probability) * 0.3) + \n",
        "    (CASE service_tier WHEN 'Elite' THEN 0.3 WHEN 'Premium' THEN 0.2 ELSE 0.1 END)\n",
        "  , 4) as business_priority_score\n",
        "  \n",
        "FROM target_generation\n",
        "\"\"\"\n",
        "\n",
        "# Execute feature creation\n",
        "session.sql(targets_lifecycle_sql).collect()\n",
        "\n",
        "# Verify results\n",
        "tl_count = session.sql(\"SELECT COUNT(*) as count FROM targets_lifecycle_features\").collect()[0]['COUNT']\n",
        "print(f\"‚úÖ Created target & lifecycle features for {tl_count:,} clients\")\n",
        "\n",
        "# Show target distributions\n",
        "print(\"\\nüé≤ Target variable distributions:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        lifecycle_stage,\n",
        "        COUNT(*) as client_count,\n",
        "        ROUND(AVG(conversion_probability), 4) as avg_conversion_prob,\n",
        "        ROUND(AVG(churn_probability), 4) as avg_churn_prob,\n",
        "        SUM(conversion_target) as conversion_targets,\n",
        "        SUM(churn_target) as churn_targets\n",
        "    FROM targets_lifecycle_features\n",
        "    GROUP BY lifecycle_stage\n",
        "    ORDER BY client_count DESC\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"\\nüìã Next best action distribution:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        next_best_action,\n",
        "        COUNT(*) as client_count,\n",
        "        ROUND(AVG(business_priority_score), 4) as avg_priority_score\n",
        "    FROM targets_lifecycle_features\n",
        "    GROUP BY next_best_action\n",
        "    ORDER BY client_count DESC\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Unified Feature Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create unified feature store combining all feature sets\n",
        "print(\"üè™ Creating unified feature store...\")\n",
        "\n",
        "# Check for all required dependencies\n",
        "required_tables = ['engagement_features', 'financial_behavioral_features', 'targets_lifecycle_features']\n",
        "missing_tables = []\n",
        "\n",
        "for table in required_tables:\n",
        "    try:\n",
        "        table_check = session.sql(f\"\"\"\n",
        "            SELECT COUNT(*) as table_exists \n",
        "            FROM INFORMATION_SCHEMA.TABLES \n",
        "            WHERE TABLE_NAME = '{table.upper()}' \n",
        "            AND TABLE_SCHEMA = CURRENT_SCHEMA()\n",
        "        \"\"\").collect()[0]['TABLE_EXISTS']\n",
        "        \n",
        "        if table_check == 0:\n",
        "            missing_tables.append(table)\n",
        "        else:\n",
        "            print(f\"‚úÖ {table} table verified\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Warning checking {table}: {e}\")\n",
        "        missing_tables.append(table)\n",
        "\n",
        "if missing_tables:\n",
        "    print(\"‚ùå ERROR: Missing required feature tables!\")\n",
        "    for table in missing_tables:\n",
        "        print(f\"   üìã Missing: {table}\")\n",
        "    print(\"   üîÑ Please run all previous feature engineering cells first\")\n",
        "    raise Exception(f\"Missing dependencies: {', '.join(missing_tables)}\")\n",
        "\n",
        "print(\"‚úÖ All feature tables verified - proceeding with unified feature store creation\")\n",
        "\n",
        "unified_feature_store_sql = \"\"\"\n",
        "CREATE OR REPLACE TABLE feature_store AS\n",
        "SELECT \n",
        "  ef.client_id,\n",
        "  ef.feature_timestamp,\n",
        "  \n",
        "  -- Engagement features\n",
        "  ef.total_events_7d, ef.web_visits_7d, ef.email_opens_7d, ef.email_clicks_7d,\n",
        "  ef.total_events_30d, ef.web_visits_30d, ef.email_opens_30d, ef.email_clicks_30d, ef.personal_interactions_30d,\n",
        "  ef.total_events_90d, ef.web_visits_90d,\n",
        "  ef.avg_session_duration_30d, ef.active_days_30d,\n",
        "  ef.total_touchpoint_value_30d, ef.avg_touchpoint_value_30d, ef.conversions_30d,\n",
        "  ef.days_since_last_activity, ef.engagement_frequency_30d, ef.email_click_rate_30d,\n",
        "  ef.engagement_trend_30d, ef.engagement_score_30d,\n",
        "  \n",
        "  -- Financial & behavioral features\n",
        "  fbf.age, fbf.annual_income, fbf.current_401k_balance, fbf.years_to_retirement,\n",
        "  fbf.total_assets_under_management, fbf.client_tenure_months,\n",
        "  fbf.income_to_age_ratio, fbf.assets_to_income_ratio,\n",
        "  fbf.retirement_readiness_score, fbf.wealth_growth_potential, fbf.premium_client_indicator,\n",
        "  fbf.service_tier_numeric, fbf.risk_tolerance_numeric, fbf.investment_experience_numeric,\n",
        "  fbf.total_lifetime_events, fbf.engagement_span_days, fbf.education_engagement, fbf.advisor_meetings_total,\n",
        "  fbf.web_preference_ratio, fbf.email_preference_ratio, fbf.phone_preference_ratio, fbf.inperson_preference_ratio,\n",
        "  fbf.mobile_adoption_score, fbf.lifetime_engagement_frequency, fbf.avg_touchpoint_value,\n",
        "  \n",
        "  -- Lifecycle & target features\n",
        "  tlf.lifecycle_stage, tlf.age_segment, tlf.tenure_segment,\n",
        "  tlf.conversion_probability, tlf.churn_probability,\n",
        "  tlf.conversion_target, tlf.churn_target, tlf.next_best_action,\n",
        "  tlf.business_priority_score\n",
        "  \n",
        "FROM engagement_features ef\n",
        "LEFT JOIN financial_behavioral_features fbf ON ef.client_id = fbf.client_id\n",
        "LEFT JOIN targets_lifecycle_features tlf ON ef.client_id = tlf.client_id\n",
        "WHERE ef.client_id IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "# Execute unified feature store creation\n",
        "session.sql(unified_feature_store_sql).collect()\n",
        "\n",
        "# Verify and analyze feature store\n",
        "fs_count = session.sql(\"SELECT COUNT(*) as count FROM feature_store\").collect()[0]['COUNT']\n",
        "feature_count = session.sql(\"SELECT COUNT(*) as feature_count FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'FEATURE_STORE'\").collect()[0]['FEATURE_COUNT']\n",
        "\n",
        "print(f\"‚úÖ Created unified feature store:\")\n",
        "print(f\"   üìä Records: {fs_count:,} clients\")\n",
        "print(f\"   üîß Features: {feature_count} total features\")\n",
        "\n",
        "# Feature completeness analysis\n",
        "print(\"\\nüîç Feature completeness analysis:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        COUNT(*) as total_records,\n",
        "        COUNT(CASE WHEN engagement_score_30d IS NOT NULL THEN 1 END) as with_engagement_score,\n",
        "        COUNT(CASE WHEN retirement_readiness_score IS NOT NULL THEN 1 END) as with_retirement_score,\n",
        "        COUNT(CASE WHEN conversion_target IS NOT NULL THEN 1 END) as with_conversion_target,\n",
        "        COUNT(CASE WHEN churn_target IS NOT NULL THEN 1 END) as with_churn_target,\n",
        "        ROUND(\n",
        "            COUNT(CASE WHEN engagement_score_30d IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 2\n",
        "        ) as completeness_percentage\n",
        "    FROM feature_store\n",
        "\"\"\").show()\n",
        "\n",
        "# Feature statistics\n",
        "print(\"\\nüìà Key feature statistics:\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        ROUND(AVG(engagement_score_30d), 4) as avg_engagement_score,\n",
        "        ROUND(AVG(retirement_readiness_score), 4) as avg_retirement_readiness,\n",
        "        ROUND(AVG(conversion_probability), 4) as avg_conversion_prob,\n",
        "        ROUND(AVG(churn_probability), 4) as avg_churn_prob,\n",
        "        SUM(conversion_target) as total_conversion_targets,\n",
        "        SUM(churn_target) as total_churn_targets\n",
        "    FROM feature_store\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Initialize Snowflake Feature Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Verify Features are Ready\n",
        "print(\"=== Feature Engineering Complete ===\\n\")\n",
        "\n",
        "# Verify feature table\n",
        "try:\n",
        "    feature_count = session.table(\"FEATURE_STORE\").count()\n",
        "    feature_cols = len(session.table(\"FEATURE_STORE\").columns)\n",
        "    \n",
        "    print(f\"‚úÖ FEATURE_STORE table:\")\n",
        "    print(f\"   - Records: {feature_count:,}\")\n",
        "    print(f\"   - Columns: {feature_cols}\")\n",
        "    print(f\"   - Location: {session.get_current_database()}.{session.get_current_schema()}.FEATURE_STORE\")\n",
        "    \n",
        "    # Show sample features\n",
        "    print(\"\\nüìà Sample High-Value Clients:\")\n",
        "    session.table(\"FEATURE_STORE\").filter(\n",
        "        \"WEALTH_GROWTH_POTENTIAL > 0.7\"\n",
        "    ).select(\n",
        "        \"CLIENT_ID\",\n",
        "        \"ENGAGEMENT_SCORE_30D\",\n",
        "        \"RETIREMENT_READINESS_SCORE\",\n",
        "        \"ANNUAL_INCOME\",\n",
        "        \"LIFECYCLE_STAGE\"\n",
        "    ).limit(5).show()\n",
        "    \n",
        "    print(\"\\n‚úÖ FEATURES READY FOR MODEL TRAINING!\")\n",
        "    print(\"\\nüöÄ Next Steps:\")\n",
        "    print(\"1. Optional: Run Cell 11 to register in Feature Store UI\")\n",
        "    print(\"2. Proceed to 03_Model_Training_Registry_Snowflake.ipynb\")\n",
        "    print(\"3. Use: features_df = session.table('FEATURE_STORE')\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Make sure you've run cells 1-9 in order!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Register in Snowflake Feature Store UI\n",
        "\n",
        "The cell below registers your features in Snowflake's Feature Store for UI visibility. This is optional - your features are already ready for ML training in the FEATURE_STORE table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Register in Snowflake Feature Store (Optional)\n",
        "print(\"Registering features in Snowflake Feature Store...\")\n",
        "\n",
        "from snowflake.ml.feature_store import FeatureStore, Entity, FeatureView, CreationMode\n",
        "import pandas as pd\n",
        "\n",
        "# Create a new database to avoid any corruption issues\n",
        "new_db = f\"FINANCIAL_ML_DEMO_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "print(f\"Creating new database: {new_db}\")\n",
        "\n",
        "session.sql(f\"CREATE DATABASE IF NOT EXISTS {new_db}\").collect()\n",
        "session.sql(f\"USE DATABASE {new_db}\").collect()\n",
        "session.sql(\"CREATE SCHEMA IF NOT EXISTS ML_PIPELINE\").collect()\n",
        "session.sql(\"USE SCHEMA ML_PIPELINE\").collect()\n",
        "\n",
        "# Copy your feature table to the new database\n",
        "print(\"Copying features to new database...\")\n",
        "original_db = \"FINANCIAL_ML_DB\"  # Update if different\n",
        "session.sql(f\"\"\"\n",
        "    CREATE TABLE FEATURE_STORE AS \n",
        "    SELECT * FROM {original_db}.ML_PIPELINE.FEATURE_STORE\n",
        "\"\"\").collect()\n",
        "\n",
        "# Now register Feature Store in the clean database\n",
        "fs = FeatureStore(\n",
        "    session=session,\n",
        "    database=new_db,\n",
        "    name=\"FEATURE_STORE\",\n",
        "    default_warehouse=session.get_current_warehouse(),\n",
        "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
        ")\n",
        "\n",
        "# Register entity and feature view\n",
        "client_entity = Entity(name=\"client\", join_keys=[\"CLIENT_ID\"])\n",
        "fs.register_entity(client_entity)\n",
        "\n",
        "client_fv = FeatureView(\n",
        "    name=\"client_features_v1\",\n",
        "    entities=[client_entity],\n",
        "    feature_df=session.table(\"FEATURE_STORE\")\n",
        ")\n",
        "\n",
        "fs.register_feature_view(client_fv, version=\"1.0\")\n",
        "\n",
        "print(f\"\\n‚úÖ SUCCESS! Feature Store registered in: {new_db}\")\n",
        "print(\"Check Snowsight ‚Üí AI & ML ‚Üí Feature Store\")\n",
        "print(f\"\\nüìù IMPORTANT: Update your Model Training notebook to use:\")\n",
        "print(f\"   Database: {new_db}\")\n",
        "print(f\"   Table: {new_db}.ML_PIPELINE.FEATURE_STORE\")\n",
        "print(f\"\\nSave this database name: {new_db}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
