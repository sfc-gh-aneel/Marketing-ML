# Snowflake-Native Event Streaming Setup

## ðŸŽ¯ How It Works

Instead of generating local JSON files, events are sent directly to **Snowflake internal stages** where **Snowpipe** automatically ingests them.

## ðŸ—ï¸ Architecture

```
Event Generator â†’ Snowflake Internal Stage â†’ Snowpipe â†’ marketing_events table
```

## âš™ï¸ Setup (Already included in snowflake_setup.sql)

```sql
-- Internal stage for events
CREATE STAGE marketing_events_stage;

-- Snowpipe for automatic ingestion
CREATE PIPE marketing_events_pipe AS
COPY INTO marketing_events
FROM @marketing_events_stage
FILE_FORMAT = (TYPE = JSON);
```

## ðŸŽ¬ Demo Usage

```bash
# Run the streaming demo
python demo_streaming.py

# Events are now sent to Snowflake stage (simulated in demo mode)
# In production: Events â†’ @marketing_events_stage â†’ Snowpipe â†’ table
```

## ðŸ” Monitor Ingestion

```sql
-- Check pipe status
SELECT SYSTEM$PIPE_STATUS('marketing_events_pipe');

-- View recent events
SELECT * FROM marketing_events 
WHERE event_timestamp >= DATEADD(minute, -10, CURRENT_TIMESTAMP())
ORDER BY event_timestamp DESC;

-- Check stage contents
LIST @marketing_events_stage;
```

## âœ¨ Benefits

- **Snowflake-native**: No external file system needed
- **Auto-ingestion**: Snowpipe handles everything automatically  
- **Scalable**: Handles high-volume event streams
- **Reliable**: Built-in error handling and retry logic
- **Cost-effective**: Pay only for what you ingest

Perfect for demonstrating real-time ML pipeline capabilities! ðŸš€
